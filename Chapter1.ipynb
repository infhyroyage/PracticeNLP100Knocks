{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [第1章: 準備運動](http://www.cl.ecei.tohoku.ac.jp/nlp100/#ch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"stressed\"\n",
    "\n",
    "bar = \"\"\n",
    "for char in foo:\n",
    "    bar = char + bar\n",
    "\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"パタトクカシーー\"\n",
    "\n",
    "bar = \"\"\n",
    "for idx in range(0, 8, 2):\n",
    "    bar = bar + foo[idx]\n",
    "\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "foo = \"パトカー\"\n",
    "bar = \"タクシー\"\n",
    "\n",
    "for idx in range(len(foo)):\n",
    "    print(foo[idx], end=\"\")\n",
    "    print(bar[idx], end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Now',\n",
       " 'I',\n",
       " 'need',\n",
       " 'a',\n",
       " 'drink',\n",
       " 'alcoholic',\n",
       " 'of',\n",
       " 'course',\n",
       " 'after',\n",
       " 'the',\n",
       " 'heavy',\n",
       " 'lectures',\n",
       " 'involving',\n",
       " 'quantum',\n",
       " 'mechanics']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "foo = []\n",
    "bar = \"\"\n",
    "for char in sentence:\n",
    "    if char==\" \" or char==\",\" or char==\".\":\n",
    "        if bar!=\"\":\n",
    "            foo.append(bar)\n",
    "            bar = \"\"\n",
    "    else:\n",
    "        bar = bar + char\n",
    "\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'H',\n",
       " 2: 'He',\n",
       " 3: 'Li',\n",
       " 4: 'Be',\n",
       " 5: 'B',\n",
       " 6: 'C',\n",
       " 7: 'N',\n",
       " 8: 'O',\n",
       " 9: 'F',\n",
       " 10: 'Ne',\n",
       " 11: 'Na',\n",
       " 12: 'Mi',\n",
       " 13: 'Al',\n",
       " 14: 'Si',\n",
       " 15: 'P',\n",
       " 16: 'S',\n",
       " 17: 'Cl',\n",
       " 18: 'Ar',\n",
       " 19: 'K',\n",
       " 20: 'Ca'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "foo = []\n",
    "bar = \"\"\n",
    "for char in sentence:\n",
    "    if char==\" \" or char==\",\" or char==\".\":\n",
    "        if bar!=\"\":\n",
    "            foo.append(bar)\n",
    "            bar = \"\"\n",
    "    else:\n",
    "        bar = bar + char\n",
    "\n",
    "bar = {}\n",
    "for idx, word in enumerate(foo):\n",
    "    if idx==0 or idx==4 or idx==5 or idx==6 or idx==7 or idx==8 or idx==14 or idx==15 or idx==18:\n",
    "        bar[idx+1] = word[0]\n",
    "    else:\n",
    "        bar[idx+1] = word[0] + word[1]\n",
    "\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram(sequence, n: int):\n",
    "    n_gram = []\n",
    "    foo = \"\"\n",
    "    for i in range(len(sequence)-n+1):\n",
    "        for j in range(i, i+n):\n",
    "            foo = foo + sequence[j]\n",
    "        n_gram.append(foo)\n",
    "        foo = \"\"\n",
    "\n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iam', 'aman', 'anNLPer']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語bi-gram\n",
    "sentence = \"I am an NLPer\"\n",
    "\n",
    "foo = create_n_gram(sentence.split(), 2)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文字bi-gram\n",
    "sentence = \"I am an NLPer\"\n",
    "\n",
    "foo = create_n_gram(sentence, 2)\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 : {'gr', 'ph', 'di', 'se', 'ar', 'ag', 'ra', 'pa', 'is', 'ad', 'ap'}\n",
      "積集合 : {'pa', 'ar', 'ra', 'ap'}\n",
      "差集合(X\\Y) : {'se', 'is', 'ad', 'di'}\n",
      "差集合(Y\\X) : {'gr', 'ph', 'ag'}\n"
     ]
    }
   ],
   "source": [
    "X = set(create_n_gram(\"paraparaparadise\", 2))\n",
    "Y = set(create_n_gram(\"paragraph\", 2))\n",
    "\n",
    "print(\"和集合 : \" + str(X|Y))\n",
    "print(\"積集合 : \" + str(X&Y))\n",
    "print(\"差集合(X\\Y) : \" + str(X-Y))\n",
    "print(\"差集合(Y\\X) : \" + str(Y-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"se\" is included in X : True\n",
      "\"se\" is included in Y : False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\"se\\\" is included in X : \" + str(\"se\" in X))\n",
    "print(\"\\\"se\\\" is included in Y : \" + str(\"se\" in Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_template(x, y, z):\n",
    "    return str(x) + \"時の\" + str(y) + \"は\" + str(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z = 12, \"気温\", 22.4\n",
    "\n",
    "foo = create_template(x, y, z)\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "英小文字ならば(219 - 文字コード)の文字に置換\n",
    "その他の文字はそのまま出力\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "a\n",
      "122\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "print(ord(\"a\"))\n",
    "print(chr(97))\n",
    "print(ord(\"z\"))\n",
    "print(chr(122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(sentence: str):\n",
    "    encode = \"\"\n",
    "    for char in sentence:\n",
    "        if ord(\"a\") <= ord(char) <= ord(\"z\"):\n",
    "            encode = encode + chr(219-ord(char))\n",
    "        else:\n",
    "            encode = encode + char\n",
    "\n",
    "    return encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I xlfowm'g yvorvev gszg I xlfow zxgfzoob fmwvihgzmw dszg I dzh ivzwrmt : gsv ksvmlnvmzo kldvi lu gsv sfnzm nrmw .\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "encode = cipher(sentence)\n",
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rehpic(sentence: str):\n",
    "    decode = \"\"\n",
    "    for char in sentence:\n",
    "        if 219-ord(\"z\") <= ord(char) <= 219-ord(\"a\"):\n",
    "            decode = decode + chr(219-ord(char))\n",
    "        else:\n",
    "            decode = decode + char\n",
    "\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode = cipher(encode)\n",
    "decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typoglycemia(sentence: str):\n",
    "    if len(sentence) <= 4:\n",
    "        return sentence\n",
    "\n",
    "    from random import sample\n",
    "    foo = sentence[1:-1]\n",
    "    bar = \"\"\n",
    "    for char in sample(foo, len(foo)):\n",
    "        bar += char\n",
    "    return sentence[0] + bar + sentence[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I  umhn tavc dsuwr  hnchafa Imetod'hsepur lu tmaan to d o len alhaeehdlnicdbwo tloeyu pnd:n aeraee twil tIe ntig.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "typoglycemia(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toclpymgyiea'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Typoglycemia\"\n",
    "\n",
    "typoglycemia(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"foo\"\n",
    "\n",
    "typoglycemia(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
