{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [第6章: 英語テキストの処理](http://www.cl.ecei.tohoku.ac.jp/nlp100/#ch6)\n",
    "英語のテキスト（[nlp.txt](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/nlp.txt)）に対して，以下の処理を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Corpus/nlp.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Corpus/nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. 文区切り\n",
    "(. or ; or : or ? or !) → 空白文字 → 英大文字というパターンを文の区切りと見なし，入力された文書を1行1文の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open(\"../Corpus/nlp.txt\") as f:\n",
    "    for line in f:\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        idx, idx_start = 0, 0\n",
    "        while idx < len(line):\n",
    "            if re.match(\"[.;:?!] [A-Z]\", line[idx:idx+3]):\n",
    "                sentences.append(line[idx_start:idx+1])\n",
    "                idx += 2\n",
    "                idx_start = idx\n",
    "            else:\n",
    "                idx += 1\n",
    "        sentences.append(line[idx_start:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "From Wikipedia, the free encyclopedia\n",
      "Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages.\n",
      "As such, NLP is related to the area of humani-computer interaction.\n",
      "Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.\n",
      "History\n",
      "The history of NLP generally starts in the 1950s, although work can be found from earlier periods.\n",
      "In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.\n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English.\n",
      "The authors claimed that within three or five years, machine translation would be a solved problem.\n",
      "However, real progress was much slower, and after the ALPAC report in 1966, which found that ten year long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.\n",
      "Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\n",
      "Some notably successful NLP systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 to 1966.\n",
      "Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction.\n",
      "When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\n",
      "During the 1970s many programmers began to write 'conceptual ontologies', which structured real-world information into computer-understandable data.\n",
      "Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).\n",
      "During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.\n",
      "Up to the 1980s, most NLP systems were based on complex sets of hand-written rules.\n",
      "Starting in the late 1980s, however, there was a revolution in NLP with the introduction of machine learning algorithms for language processing.\n",
      "This was due to both the steady increase in computational power resulting from Moore's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.\n",
      "Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.\n",
      "However, Part of speech tagging introduced the use of Hidden Markov Models to NLP, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data.\n",
      "The cache language models upon which many speech recognition systems now rely are examples of such statistical models.\n",
      "Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\n",
      "Many of the notable early successes occurred in the field of machine translation, due especially to work at IBM Research, where successively more complicated statistical models were developed.\n",
      "These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.\n",
      "However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems.\n",
      "As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n",
      "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.\n",
      "Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data.\n",
      "Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.\n",
      "However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the inferior results.\n",
      "NLP using machine learning\n",
      "Modern NLP algorithms are based on machine learning, especially statistical machine learning.\n",
      "The paradigm of machine learning is different from that of most prior attempts at language processing.\n",
      "Prior implementations of language-processing tasks typically involved the direct hand coding of large sets of rules.\n",
      "The machine-learning paradigm calls instead for using general learning algorithms - often, although not always, grounded in statistical inference - to automatically learn such rules through the analysis of large corpora of typical real-world examples.\n",
      "A corpus (plural, \"corpora\") is a set of documents (or sometimes, individual sentences) that have been hand-annotated with the correct values to be learned.\n",
      "Many different classes of machine learning algorithms have been applied to NLP tasks.\n",
      "These algorithms take as input a large set of \"features\" that are generated from the input data.\n",
      "Some of the earliest-used algorithms, such as decision trees, produced systems of hard if-then rules similar to the systems of hand-written rules that were then common.\n",
      "Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature.\n",
      "Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\n",
      "Systems based on machine-learning algorithms have many advantages over hand-produced rules:\n",
      "The learning procedures used during machine learning automatically focus on the most common cases, whereas when writing rules by hand it is often not obvious at all where the effort should be directed.\n",
      "Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted).\n",
      "Generally, handling such input gracefully with hand-written rules -- or more generally, creating systems of hand-written rules that make soft decisions -- extremely difficult, error-prone and time-consuming.\n",
      "Systems based on automatically learning the rules can be made more accurate simply by supplying more input data.\n",
      "However, systems based on hand-written rules can only be made more accurate by increasing the complexity of the rules, which is a much more difficult task.\n",
      "In particular, there is a limit to the complexity of systems based on hand-crafted rules, beyond which the systems become more and more unmanageable.\n",
      "However, creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked, generally without significant increases in the complexity of the annotation process.\n",
      "The subfield of NLP devoted to learning approaches is known as Natural Language Learning (NLL) and its conference CoNLL and peak body SIGNLL are sponsored by ACL, recognizing also their links with Computational Linguistics and Language Acquisition.\n",
      "When the aims of computational language learning research is to understand more about human language acquisition, or psycholinguistics, NLL overlaps into the related field of Computational Psycholinguistics.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51. 単語の切り出し\n",
    "空白を単語の区切りとみなし，50の出力を入力として受け取り，1行1単語の形式で出力せよ．ただし，文の終端では空行を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "\n",
      "From\n",
      "Wikipedia,\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "(NLP)\n",
      "is\n",
      "a\n",
      "field\n",
      "of\n",
      "computer\n",
      "science,\n",
      "artificial\n",
      "intelligence,\n",
      "and\n",
      "linguistics\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interactions\n",
      "between\n",
      "computers\n",
      "and\n",
      "human\n",
      "(natural)\n",
      "languages.\n",
      "\n",
      "As\n",
      "such,\n",
      "NLP\n",
      "is\n",
      "related\n",
      "to\n",
      "the\n",
      "area\n",
      "of\n",
      "humani-computer\n",
      "interaction.\n",
      "\n",
      "Many\n",
      "challenges\n",
      "in\n",
      "NLP\n",
      "involve\n",
      "natural\n",
      "language\n",
      "understanding,\n",
      "that\n",
      "is,\n",
      "enabling\n",
      "computers\n",
      "to\n",
      "derive\n",
      "meaning\n",
      "from\n",
      "human\n",
      "or\n",
      "natural\n",
      "language\n",
      "input,\n",
      "and\n",
      "others\n",
      "involve\n",
      "natural\n",
      "language\n",
      "generation.\n",
      "\n",
      "History\n",
      "\n",
      "The\n",
      "history\n",
      "of\n",
      "NLP\n",
      "generally\n",
      "starts\n",
      "in\n",
      "the\n",
      "1950s,\n",
      "although\n",
      "work\n",
      "can\n",
      "be\n",
      "found\n",
      "from\n",
      "earlier\n",
      "periods.\n",
      "\n",
      "In\n",
      "1950,\n",
      "Alan\n",
      "Turing\n",
      "published\n",
      "an\n",
      "article\n",
      "titled\n",
      "\"Computing\n",
      "Machinery\n",
      "and\n",
      "Intelligence\"\n",
      "which\n",
      "proposed\n",
      "what\n",
      "is\n",
      "now\n",
      "called\n",
      "the\n",
      "Turing\n",
      "test\n",
      "as\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intelligence.\n",
      "\n",
      "The\n",
      "Georgetown\n",
      "experiment\n",
      "in\n",
      "1954\n",
      "involved\n",
      "fully\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "more\n",
      "than\n",
      "sixty\n",
      "Russian\n",
      "sentences\n",
      "into\n",
      "English.\n",
      "\n",
      "The\n",
      "authors\n",
      "claimed\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "years,\n",
      "machine\n",
      "translation\n",
      "would\n",
      "be\n",
      "a\n",
      "solved\n",
      "problem.\n",
      "\n",
      "However,\n",
      "real\n",
      "progress\n",
      "was\n",
      "much\n",
      "slower,\n",
      "and\n",
      "after\n",
      "the\n",
      "ALPAC\n",
      "report\n",
      "in\n",
      "1966,\n",
      "which\n",
      "found\n",
      "that\n",
      "ten\n",
      "year\n",
      "long\n",
      "research\n",
      "had\n",
      "failed\n",
      "to\n",
      "fulfill\n",
      "the\n",
      "expectations,\n",
      "funding\n",
      "for\n",
      "machine\n",
      "translation\n",
      "was\n",
      "dramatically\n",
      "reduced.\n",
      "\n",
      "Little\n",
      "further\n",
      "research\n",
      "in\n",
      "machine\n",
      "translation\n",
      "was\n",
      "conducted\n",
      "until\n",
      "the\n",
      "late\n",
      "1980s,\n",
      "when\n",
      "the\n",
      "first\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "systems\n",
      "were\n",
      "developed.\n",
      "\n",
      "Some\n",
      "notably\n",
      "successful\n",
      "NLP\n",
      "systems\n",
      "developed\n",
      "in\n",
      "the\n",
      "1960s\n",
      "were\n",
      "SHRDLU,\n",
      "a\n",
      "natural\n",
      "language\n",
      "system\n",
      "working\n",
      "in\n",
      "restricted\n",
      "\"blocks\n",
      "worlds\"\n",
      "with\n",
      "restricted\n",
      "vocabularies,\n",
      "and\n",
      "ELIZA,\n",
      "a\n",
      "simulation\n",
      "of\n",
      "a\n",
      "Rogerian\n",
      "psychotherapist,\n",
      "written\n",
      "by\n",
      "Joseph\n",
      "Weizenbaum\n",
      "between\n",
      "1964\n",
      "to\n",
      "1966.\n",
      "\n",
      "Using\n",
      "almost\n",
      "no\n",
      "information\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emotion,\n",
      "ELIZA\n",
      "sometimes\n",
      "provided\n",
      "a\n",
      "startlingly\n",
      "human-like\n",
      "interaction.\n",
      "\n",
      "When\n",
      "the\n",
      "\"patient\"\n",
      "exceeded\n",
      "the\n",
      "very\n",
      "small\n",
      "knowledge\n",
      "base,\n",
      "ELIZA\n",
      "might\n",
      "provide\n",
      "a\n",
      "generic\n",
      "response,\n",
      "for\n",
      "example,\n",
      "responding\n",
      "to\n",
      "\"My\n",
      "head\n",
      "hurts\"\n",
      "with\n",
      "\"Why\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurts?\".\n",
      "\n",
      "During\n",
      "the\n",
      "1970s\n",
      "many\n",
      "programmers\n",
      "began\n",
      "to\n",
      "write\n",
      "'conceptual\n",
      "ontologies',\n",
      "which\n",
      "structured\n",
      "real-world\n",
      "information\n",
      "into\n",
      "computer-understandable\n",
      "data.\n",
      "\n",
      "Examples\n",
      "are\n",
      "MARGIE\n",
      "(Schank,\n",
      "1975),\n",
      "SAM\n",
      "(Cullingford,\n",
      "1978),\n",
      "PAM\n",
      "(Wilensky,\n",
      "1978),\n",
      "TaleSpin\n",
      "(Meehan,\n",
      "1976),\n",
      "QUALM\n",
      "(Lehnert,\n",
      "1977),\n",
      "Politics\n",
      "(Carbonell,\n",
      "1979),\n",
      "and\n",
      "Plot\n",
      "Units\n",
      "(Lehnert\n",
      "1981).\n",
      "\n",
      "During\n",
      "this\n",
      "time,\n",
      "many\n",
      "chatterbots\n",
      "were\n",
      "written\n",
      "including\n",
      "PARRY,\n",
      "Racter,\n",
      "and\n",
      "Jabberwacky.\n",
      "\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s,\n",
      "most\n",
      "NLP\n",
      "systems\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "sets\n",
      "of\n",
      "hand-written\n",
      "rules.\n",
      "\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s,\n",
      "however,\n",
      "there\n",
      "was\n",
      "a\n",
      "revolution\n",
      "in\n",
      "NLP\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "for\n",
      "language\n",
      "processing.\n",
      "\n",
      "This\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "resulting\n",
      "from\n",
      "Moore's\n",
      "Law\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theories\n",
      "of\n",
      "linguistics\n",
      "(e.g.\n",
      "transformational\n",
      "grammar),\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing.\n",
      "\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "machine\n",
      "learning\n",
      "algorithms,\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees,\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "existing\n",
      "hand-written\n",
      "rules.\n",
      "\n",
      "However,\n",
      "Part\n",
      "of\n",
      "speech\n",
      "tagging\n",
      "introduced\n",
      "the\n",
      "use\n",
      "of\n",
      "Hidden\n",
      "Markov\n",
      "Models\n",
      "to\n",
      "NLP,\n",
      "and\n",
      "increasingly,\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models,\n",
      "which\n",
      "make\n",
      "soft,\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "the\n",
      "features\n",
      "making\n",
      "up\n",
      "the\n",
      "input\n",
      "data.\n",
      "\n",
      "The\n",
      "cache\n",
      "language\n",
      "models\n",
      "upon\n",
      "which\n",
      "many\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "now\n",
      "rely\n",
      "are\n",
      "examples\n",
      "of\n",
      "such\n",
      "statistical\n",
      "models.\n",
      "\n",
      "Such\n",
      "models\n",
      "are\n",
      "generally\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input,\n",
      "especially\n",
      "input\n",
      "that\n",
      "contains\n",
      "errors\n",
      "(as\n",
      "is\n",
      "very\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data),\n",
      "and\n",
      "produce\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "integrated\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "comprising\n",
      "multiple\n",
      "subtasks.\n",
      "\n",
      "Many\n",
      "of\n",
      "the\n",
      "notable\n",
      "early\n",
      "successes\n",
      "occurred\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machine\n",
      "translation,\n",
      "due\n",
      "especially\n",
      "to\n",
      "work\n",
      "at\n",
      "IBM\n",
      "Research,\n",
      "where\n",
      "successively\n",
      "more\n",
      "complicated\n",
      "statistical\n",
      "models\n",
      "were\n",
      "developed.\n",
      "\n",
      "These\n",
      "systems\n",
      "were\n",
      "able\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "existing\n",
      "multilingual\n",
      "textual\n",
      "corpora\n",
      "that\n",
      "had\n",
      "been\n",
      "produced\n",
      "by\n",
      "the\n",
      "Parliament\n",
      "of\n",
      "Canada\n",
      "and\n",
      "the\n",
      "European\n",
      "Union\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "laws\n",
      "calling\n",
      "for\n",
      "the\n",
      "translation\n",
      "of\n",
      "all\n",
      "governmental\n",
      "proceedings\n",
      "into\n",
      "all\n",
      "official\n",
      "languages\n",
      "of\n",
      "the\n",
      "corresponding\n",
      "systems\n",
      "of\n",
      "government.\n",
      "\n",
      "However,\n",
      "most\n",
      "other\n",
      "systems\n",
      "depended\n",
      "on\n",
      "corpora\n",
      "specifically\n",
      "developed\n",
      "for\n",
      "the\n",
      "tasks\n",
      "implemented\n",
      "by\n",
      "these\n",
      "systems,\n",
      "which\n",
      "was\n",
      "(and\n",
      "often\n",
      "continues\n",
      "to\n",
      "be)\n",
      "a\n",
      "major\n",
      "limitation\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "systems.\n",
      "\n",
      "As\n",
      "a\n",
      "result,\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "has\n",
      "gone\n",
      "into\n",
      "methods\n",
      "of\n",
      "more\n",
      "effectively\n",
      "learning\n",
      "from\n",
      "limited\n",
      "amounts\n",
      "of\n",
      "data.\n",
      "\n",
      "Recent\n",
      "research\n",
      "has\n",
      "increasingly\n",
      "focused\n",
      "on\n",
      "unsupervised\n",
      "and\n",
      "semi-supervised\n",
      "learning\n",
      "algorithms.\n",
      "\n",
      "Such\n",
      "algorithms\n",
      "are\n",
      "able\n",
      "to\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "has\n",
      "not\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "desired\n",
      "answers,\n",
      "or\n",
      "using\n",
      "a\n",
      "combination\n",
      "of\n",
      "annotated\n",
      "and\n",
      "non-annotated\n",
      "data.\n",
      "\n",
      "Generally,\n",
      "this\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervised\n",
      "learning,\n",
      "and\n",
      "typically\n",
      "produces\n",
      "less\n",
      "accurate\n",
      "results\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data.\n",
      "\n",
      "However,\n",
      "there\n",
      "is\n",
      "an\n",
      "enormous\n",
      "amount\n",
      "of\n",
      "non-annotated\n",
      "data\n",
      "available\n",
      "(including,\n",
      "among\n",
      "other\n",
      "things,\n",
      "the\n",
      "entire\n",
      "content\n",
      "of\n",
      "the\n",
      "World\n",
      "Wide\n",
      "Web),\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "results.\n",
      "\n",
      "NLP\n",
      "using\n",
      "machine\n",
      "learning\n",
      "\n",
      "Modern\n",
      "NLP\n",
      "algorithms\n",
      "are\n",
      "based\n",
      "on\n",
      "machine\n",
      "learning,\n",
      "especially\n",
      "statistical\n",
      "machine\n",
      "learning.\n",
      "\n",
      "The\n",
      "paradigm\n",
      "of\n",
      "machine\n",
      "learning\n",
      "is\n",
      "different\n",
      "from\n",
      "that\n",
      "of\n",
      "most\n",
      "prior\n",
      "attempts\n",
      "at\n",
      "language\n",
      "processing.\n",
      "\n",
      "Prior\n",
      "implementations\n",
      "of\n",
      "language-processing\n",
      "tasks\n",
      "typically\n",
      "involved\n",
      "the\n",
      "direct\n",
      "hand\n",
      "coding\n",
      "of\n",
      "large\n",
      "sets\n",
      "of\n",
      "rules.\n",
      "\n",
      "The\n",
      "machine-learning\n",
      "paradigm\n",
      "calls\n",
      "instead\n",
      "for\n",
      "using\n",
      "general\n",
      "learning\n",
      "algorithms\n",
      "-\n",
      "often,\n",
      "although\n",
      "not\n",
      "always,\n",
      "grounded\n",
      "in\n",
      "statistical\n",
      "inference\n",
      "-\n",
      "to\n",
      "automatically\n",
      "learn\n",
      "such\n",
      "rules\n",
      "through\n",
      "the\n",
      "analysis\n",
      "of\n",
      "large\n",
      "corpora\n",
      "of\n",
      "typical\n",
      "real-world\n",
      "examples.\n",
      "\n",
      "A\n",
      "corpus\n",
      "(plural,\n",
      "\"corpora\")\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "documents\n",
      "(or\n",
      "sometimes,\n",
      "individual\n",
      "sentences)\n",
      "that\n",
      "have\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "correct\n",
      "values\n",
      "to\n",
      "be\n",
      "learned.\n",
      "\n",
      "Many\n",
      "different\n",
      "classes\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "have\n",
      "been\n",
      "applied\n",
      "to\n",
      "NLP\n",
      "tasks.\n",
      "\n",
      "These\n",
      "algorithms\n",
      "take\n",
      "as\n",
      "input\n",
      "a\n",
      "large\n",
      "set\n",
      "of\n",
      "\"features\"\n",
      "that\n",
      "are\n",
      "generated\n",
      "from\n",
      "the\n",
      "input\n",
      "data.\n",
      "\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "algorithms,\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees,\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "the\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "were\n",
      "then\n",
      "common.\n",
      "\n",
      "Increasingly,\n",
      "however,\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models,\n",
      "which\n",
      "make\n",
      "soft,\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "each\n",
      "input\n",
      "feature.\n",
      "\n",
      "Such\n",
      "models\n",
      "have\n",
      "the\n",
      "advantage\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "relative\n",
      "certainty\n",
      "of\n",
      "many\n",
      "different\n",
      "possible\n",
      "answers\n",
      "rather\n",
      "than\n",
      "only\n",
      "one,\n",
      "producing\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "included\n",
      "as\n",
      "a\n",
      "component\n",
      "of\n",
      "a\n",
      "larger\n",
      "system.\n",
      "\n",
      "Systems\n",
      "based\n",
      "on\n",
      "machine-learning\n",
      "algorithms\n",
      "have\n",
      "many\n",
      "advantages\n",
      "over\n",
      "hand-produced\n",
      "rules:\n",
      "\n",
      "The\n",
      "learning\n",
      "procedures\n",
      "used\n",
      "during\n",
      "machine\n",
      "learning\n",
      "automatically\n",
      "focus\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "cases,\n",
      "whereas\n",
      "when\n",
      "writing\n",
      "rules\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "obvious\n",
      "at\n",
      "all\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "directed.\n",
      "\n",
      "Automatic\n",
      "learning\n",
      "procedures\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statistical\n",
      "inference\n",
      "algorithms\n",
      "to\n",
      "produce\n",
      "models\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "(e.g.\n",
      "containing\n",
      "words\n",
      "or\n",
      "structures\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "before)\n",
      "and\n",
      "to\n",
      "erroneous\n",
      "input\n",
      "(e.g.\n",
      "with\n",
      "misspelled\n",
      "words\n",
      "or\n",
      "words\n",
      "accidentally\n",
      "omitted).\n",
      "\n",
      "Generally,\n",
      "handling\n",
      "such\n",
      "input\n",
      "gracefully\n",
      "with\n",
      "hand-written\n",
      "rules\n",
      "--\n",
      "or\n",
      "more\n",
      "generally,\n",
      "creating\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "make\n",
      "soft\n",
      "decisions\n",
      "--\n",
      "extremely\n",
      "difficult,\n",
      "error-prone\n",
      "and\n",
      "time-consuming.\n",
      "\n",
      "Systems\n",
      "based\n",
      "on\n",
      "automatically\n",
      "learning\n",
      "the\n",
      "rules\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "simply\n",
      "by\n",
      "supplying\n",
      "more\n",
      "input\n",
      "data.\n",
      "\n",
      "However,\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-written\n",
      "rules\n",
      "can\n",
      "only\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "by\n",
      "increasing\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "rules,\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task.\n",
      "\n",
      "In\n",
      "particular,\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complexity\n",
      "of\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-crafted\n",
      "rules,\n",
      "beyond\n",
      "which\n",
      "the\n",
      "systems\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanageable.\n",
      "\n",
      "However,\n",
      "creating\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learning\n",
      "systems\n",
      "simply\n",
      "requires\n",
      "a\n",
      "corresponding\n",
      "increase\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hours\n",
      "worked,\n",
      "generally\n",
      "without\n",
      "significant\n",
      "increases\n",
      "in\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "annotation\n",
      "process.\n",
      "\n",
      "The\n",
      "subfield\n",
      "of\n",
      "NLP\n",
      "devoted\n",
      "to\n",
      "learning\n",
      "approaches\n",
      "is\n",
      "known\n",
      "as\n",
      "Natural\n",
      "Language\n",
      "Learning\n",
      "(NLL)\n",
      "and\n",
      "its\n",
      "conference\n",
      "CoNLL\n",
      "and\n",
      "peak\n",
      "body\n",
      "SIGNLL\n",
      "are\n",
      "sponsored\n",
      "by\n",
      "ACL,\n",
      "recognizing\n",
      "also\n",
      "their\n",
      "links\n",
      "with\n",
      "Computational\n",
      "Linguistics\n",
      "and\n",
      "Language\n",
      "Acquisition.\n",
      "\n",
      "When\n",
      "the\n",
      "aims\n",
      "of\n",
      "computational\n",
      "language\n",
      "learning\n",
      "research\n",
      "is\n",
      "to\n",
      "understand\n",
      "more\n",
      "about\n",
      "human\n",
      "language\n",
      "acquisition,\n",
      "or\n",
      "psycholinguistics,\n",
      "NLL\n",
      "overlaps\n",
      "into\n",
      "the\n",
      "related\n",
      "field\n",
      "of\n",
      "Computational\n",
      "Psycholinguistics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        print(word)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52. ステミング\n",
    "51の出力を入力として受け取り，Porterのステミングアルゴリズムを適用し，単語と語幹をタブ区切り形式で出力せよ． Pythonでは，Porterのステミングアルゴリズムの実装として[stemming](https://pypi.python.org/pypi/stemming)モジュールを利用するとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\tnatur\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "\n",
      "From\tfrom\n",
      "Wikipedia,\twikipedia,\n",
      "the\tthe\n",
      "free\tfree\n",
      "encyclopedia\tencyclopedia\n",
      "\n",
      "Natural\tnatur\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "(NLP)\t(nlp)\n",
      "is\tis\n",
      "a\ta\n",
      "field\tfield\n",
      "of\tof\n",
      "computer\tcomput\n",
      "science,\tscience,\n",
      "artificial\tartifici\n",
      "intelligence,\tintelligence,\n",
      "and\tand\n",
      "linguistics\tlinguist\n",
      "concerned\tconcern\n",
      "with\twith\n",
      "the\tthe\n",
      "interactions\tinteract\n",
      "between\tbetween\n",
      "computers\tcomput\n",
      "and\tand\n",
      "human\thuman\n",
      "(natural)\t(natural)\n",
      "languages.\tlanguages.\n",
      "\n",
      "As\tAs\n",
      "such,\tsuch,\n",
      "NLP\tnlp\n",
      "is\tis\n",
      "related\trelat\n",
      "to\tto\n",
      "the\tthe\n",
      "area\tarea\n",
      "of\tof\n",
      "humani-computer\thumani-comput\n",
      "interaction.\tinteraction.\n",
      "\n",
      "Many\tmani\n",
      "challenges\tchalleng\n",
      "in\tin\n",
      "NLP\tnlp\n",
      "involve\tinvolv\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "understanding,\tunderstanding,\n",
      "that\tthat\n",
      "is,\tis,\n",
      "enabling\tenabl\n",
      "computers\tcomput\n",
      "to\tto\n",
      "derive\tderiv\n",
      "meaning\tmean\n",
      "from\tfrom\n",
      "human\thuman\n",
      "or\tor\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "input,\tinput,\n",
      "and\tand\n",
      "others\tother\n",
      "involve\tinvolv\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "generation.\tgeneration.\n",
      "\n",
      "History\thistori\n",
      "\n",
      "The\tthe\n",
      "history\thistori\n",
      "of\tof\n",
      "NLP\tnlp\n",
      "generally\tgener\n",
      "starts\tstart\n",
      "in\tin\n",
      "the\tthe\n",
      "1950s,\t1950s,\n",
      "although\talthough\n",
      "work\twork\n",
      "can\tcan\n",
      "be\tbe\n",
      "found\tfound\n",
      "from\tfrom\n",
      "earlier\tearlier\n",
      "periods.\tperiods.\n",
      "\n",
      "In\tIn\n",
      "1950,\t1950,\n",
      "Alan\talan\n",
      "Turing\tture\n",
      "published\tpublish\n",
      "an\tan\n",
      "article\tarticl\n",
      "titled\ttitl\n",
      "\"Computing\t\"comput\n",
      "Machinery\tmachineri\n",
      "and\tand\n",
      "Intelligence\"\tintelligence\"\n",
      "which\twhich\n",
      "proposed\tpropos\n",
      "what\twhat\n",
      "is\tis\n",
      "now\tnow\n",
      "called\tcall\n",
      "the\tthe\n",
      "Turing\tture\n",
      "test\ttest\n",
      "as\tas\n",
      "a\ta\n",
      "criterion\tcriterion\n",
      "of\tof\n",
      "intelligence.\tintelligence.\n",
      "\n",
      "The\tthe\n",
      "Georgetown\tgeorgetown\n",
      "experiment\texperi\n",
      "in\tin\n",
      "1954\t1954\n",
      "involved\tinvolv\n",
      "fully\tfulli\n",
      "automatic\tautomat\n",
      "translation\ttranslat\n",
      "of\tof\n",
      "more\tmore\n",
      "than\tthan\n",
      "sixty\tsixti\n",
      "Russian\trussian\n",
      "sentences\tsentenc\n",
      "into\tinto\n",
      "English.\tenglish.\n",
      "\n",
      "The\tthe\n",
      "authors\tauthor\n",
      "claimed\tclaim\n",
      "that\tthat\n",
      "within\twithin\n",
      "three\tthree\n",
      "or\tor\n",
      "five\tfive\n",
      "years,\tyears,\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "would\twould\n",
      "be\tbe\n",
      "a\ta\n",
      "solved\tsolv\n",
      "problem.\tproblem.\n",
      "\n",
      "However,\thowever,\n",
      "real\treal\n",
      "progress\tprogress\n",
      "was\twa\n",
      "much\tmuch\n",
      "slower,\tslower,\n",
      "and\tand\n",
      "after\tafter\n",
      "the\tthe\n",
      "ALPAC\talpac\n",
      "report\treport\n",
      "in\tin\n",
      "1966,\t1966,\n",
      "which\twhich\n",
      "found\tfound\n",
      "that\tthat\n",
      "ten\tten\n",
      "year\tyear\n",
      "long\tlong\n",
      "research\tresearch\n",
      "had\thad\n",
      "failed\tfail\n",
      "to\tto\n",
      "fulfill\tfulfil\n",
      "the\tthe\n",
      "expectations,\texpectations,\n",
      "funding\tfund\n",
      "for\tfor\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "was\twa\n",
      "dramatically\tdramat\n",
      "reduced.\treduced.\n",
      "\n",
      "Little\tlittl\n",
      "further\tfurther\n",
      "research\tresearch\n",
      "in\tin\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "was\twa\n",
      "conducted\tconduct\n",
      "until\tuntil\n",
      "the\tthe\n",
      "late\tlate\n",
      "1980s,\t1980s,\n",
      "when\twhen\n",
      "the\tthe\n",
      "first\tfirst\n",
      "statistical\tstatist\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "systems\tsystem\n",
      "were\twere\n",
      "developed.\tdeveloped.\n",
      "\n",
      "Some\tsome\n",
      "notably\tnotabl\n",
      "successful\tsuccess\n",
      "NLP\tnlp\n",
      "systems\tsystem\n",
      "developed\tdevelop\n",
      "in\tin\n",
      "the\tthe\n",
      "1960s\t1960\n",
      "were\twere\n",
      "SHRDLU,\tshrdlu,\n",
      "a\ta\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "system\tsystem\n",
      "working\twork\n",
      "in\tin\n",
      "restricted\trestrict\n",
      "\"blocks\t\"block\n",
      "worlds\"\tworlds\"\n",
      "with\twith\n",
      "restricted\trestrict\n",
      "vocabularies,\tvocabularies,\n",
      "and\tand\n",
      "ELIZA,\teliza,\n",
      "a\ta\n",
      "simulation\tsimul\n",
      "of\tof\n",
      "a\ta\n",
      "Rogerian\trogerian\n",
      "psychotherapist,\tpsychotherapist,\n",
      "written\twritten\n",
      "by\tby\n",
      "Joseph\tjoseph\n",
      "Weizenbaum\tweizenbaum\n",
      "between\tbetween\n",
      "1964\t1964\n",
      "to\tto\n",
      "1966.\t1966.\n",
      "\n",
      "Using\tuse\n",
      "almost\talmost\n",
      "no\tno\n",
      "information\tinform\n",
      "about\tabout\n",
      "human\thuman\n",
      "thought\tthought\n",
      "or\tor\n",
      "emotion,\temotion,\n",
      "ELIZA\teliza\n",
      "sometimes\tsometim\n",
      "provided\tprovid\n",
      "a\ta\n",
      "startlingly\tstartlingli\n",
      "human-like\thuman-lik\n",
      "interaction.\tinteraction.\n",
      "\n",
      "When\twhen\n",
      "the\tthe\n",
      "\"patient\"\t\"patient\"\n",
      "exceeded\texceed\n",
      "the\tthe\n",
      "very\tveri\n",
      "small\tsmall\n",
      "knowledge\tknowledg\n",
      "base,\tbase,\n",
      "ELIZA\teliza\n",
      "might\tmight\n",
      "provide\tprovid\n",
      "a\ta\n",
      "generic\tgener\n",
      "response,\tresponse,\n",
      "for\tfor\n",
      "example,\texample,\n",
      "responding\trespond\n",
      "to\tto\n",
      "\"My\t\"mi\n",
      "head\thead\n",
      "hurts\"\thurts\"\n",
      "with\twith\n",
      "\"Why\t\"whi\n",
      "do\tdo\n",
      "you\tyou\n",
      "say\tsay\n",
      "your\tyour\n",
      "head\thead\n",
      "hurts?\".\thurts?\".\n",
      "\n",
      "During\tdure\n",
      "the\tthe\n",
      "1970s\t1970\n",
      "many\tmani\n",
      "programmers\tprogramm\n",
      "began\tbegan\n",
      "to\tto\n",
      "write\twrite\n",
      "'conceptual\t'conceptu\n",
      "ontologies',\tontologies',\n",
      "which\twhich\n",
      "structured\tstructur\n",
      "real-world\treal-world\n",
      "information\tinform\n",
      "into\tinto\n",
      "computer-understandable\tcomputer-understand\n",
      "data.\tdata.\n",
      "\n",
      "Examples\texampl\n",
      "are\tare\n",
      "MARGIE\tmargi\n",
      "(Schank,\t(schank,\n",
      "1975),\t1975),\n",
      "SAM\tsam\n",
      "(Cullingford,\t(cullingford,\n",
      "1978),\t1978),\n",
      "PAM\tpam\n",
      "(Wilensky,\t(wilensky,\n",
      "1978),\t1978),\n",
      "TaleSpin\ttalespin\n",
      "(Meehan,\t(meehan,\n",
      "1976),\t1976),\n",
      "QUALM\tqualm\n",
      "(Lehnert,\t(lehnert,\n",
      "1977),\t1977),\n",
      "Politics\tpolit\n",
      "(Carbonell,\t(carbonell,\n",
      "1979),\t1979),\n",
      "and\tand\n",
      "Plot\tplot\n",
      "Units\tunit\n",
      "(Lehnert\t(lehnert\n",
      "1981).\t1981).\n",
      "\n",
      "During\tdure\n",
      "this\tthi\n",
      "time,\ttime,\n",
      "many\tmani\n",
      "chatterbots\tchatterbot\n",
      "were\twere\n",
      "written\twritten\n",
      "including\tinclud\n",
      "PARRY,\tparry,\n",
      "Racter,\tracter,\n",
      "and\tand\n",
      "Jabberwacky.\tjabberwacky.\n",
      "\n",
      "Up\tUp\n",
      "to\tto\n",
      "the\tthe\n",
      "1980s,\t1980s,\n",
      "most\tmost\n",
      "NLP\tnlp\n",
      "systems\tsystem\n",
      "were\twere\n",
      "based\tbase\n",
      "on\ton\n",
      "complex\tcomplex\n",
      "sets\tset\n",
      "of\tof\n",
      "hand-written\thand-written\n",
      "rules.\trules.\n",
      "\n",
      "Starting\tstart\n",
      "in\tin\n",
      "the\tthe\n",
      "late\tlate\n",
      "1980s,\t1980s,\n",
      "however,\thowever,\n",
      "there\tthere\n",
      "was\twa\n",
      "a\ta\n",
      "revolution\trevolut\n",
      "in\tin\n",
      "NLP\tnlp\n",
      "with\twith\n",
      "the\tthe\n",
      "introduction\tintroduct\n",
      "of\tof\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "for\tfor\n",
      "language\tlanguag\n",
      "processing.\tprocessing.\n",
      "\n",
      "This\tthi\n",
      "was\twa\n",
      "due\tdue\n",
      "to\tto\n",
      "both\tboth\n",
      "the\tthe\n",
      "steady\tsteadi\n",
      "increase\tincreas\n",
      "in\tin\n",
      "computational\tcomput\n",
      "power\tpower\n",
      "resulting\tresult\n",
      "from\tfrom\n",
      "Moore's\tmoore'\n",
      "Law\tlaw\n",
      "and\tand\n",
      "the\tthe\n",
      "gradual\tgradual\n",
      "lessening\tlessen\n",
      "of\tof\n",
      "the\tthe\n",
      "dominance\tdomin\n",
      "of\tof\n",
      "Chomskyan\tchomskyan\n",
      "theories\ttheori\n",
      "of\tof\n",
      "linguistics\tlinguist\n",
      "(e.g.\t(e.g.\n",
      "transformational\ttransform\n",
      "grammar),\tgrammar),\n",
      "whose\twhose\n",
      "theoretical\ttheoret\n",
      "underpinnings\tunderpin\n",
      "discouraged\tdiscourag\n",
      "the\tthe\n",
      "sort\tsort\n",
      "of\tof\n",
      "corpus\tcorpu\n",
      "linguistics\tlinguist\n",
      "that\tthat\n",
      "underlies\tunderli\n",
      "the\tthe\n",
      "machine-learning\tmachine-learn\n",
      "approach\tapproach\n",
      "to\tto\n",
      "language\tlanguag\n",
      "processing.\tprocessing.\n",
      "\n",
      "Some\tsome\n",
      "of\tof\n",
      "the\tthe\n",
      "earliest-used\tearliest-us\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "algorithms,\talgorithms,\n",
      "such\tsuch\n",
      "as\tas\n",
      "decision\tdecis\n",
      "trees,\ttrees,\n",
      "produced\tproduc\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hard\thard\n",
      "if-then\tif-then\n",
      "rules\trule\n",
      "similar\tsimilar\n",
      "to\tto\n",
      "existing\texist\n",
      "hand-written\thand-written\n",
      "rules.\trules.\n",
      "\n",
      "However,\thowever,\n",
      "Part\tpart\n",
      "of\tof\n",
      "speech\tspeech\n",
      "tagging\ttag\n",
      "introduced\tintroduc\n",
      "the\tthe\n",
      "use\tuse\n",
      "of\tof\n",
      "Hidden\thidden\n",
      "Markov\tmarkov\n",
      "Models\tmodel\n",
      "to\tto\n",
      "NLP,\tnlp,\n",
      "and\tand\n",
      "increasingly,\tincreasingly,\n",
      "research\tresearch\n",
      "has\tha\n",
      "focused\tfocus\n",
      "on\ton\n",
      "statistical\tstatist\n",
      "models,\tmodels,\n",
      "which\twhich\n",
      "make\tmake\n",
      "soft,\tsoft,\n",
      "probabilistic\tprobabilist\n",
      "decisions\tdecis\n",
      "based\tbase\n",
      "on\ton\n",
      "attaching\tattach\n",
      "real-valued\treal-valu\n",
      "weights\tweight\n",
      "to\tto\n",
      "the\tthe\n",
      "features\tfeatur\n",
      "making\tmake\n",
      "up\tup\n",
      "the\tthe\n",
      "input\tinput\n",
      "data.\tdata.\n",
      "\n",
      "The\tthe\n",
      "cache\tcach\n",
      "language\tlanguag\n",
      "models\tmodel\n",
      "upon\tupon\n",
      "which\twhich\n",
      "many\tmani\n",
      "speech\tspeech\n",
      "recognition\trecognit\n",
      "systems\tsystem\n",
      "now\tnow\n",
      "rely\treli\n",
      "are\tare\n",
      "examples\texampl\n",
      "of\tof\n",
      "such\tsuch\n",
      "statistical\tstatist\n",
      "models.\tmodels.\n",
      "\n",
      "Such\tsuch\n",
      "models\tmodel\n",
      "are\tare\n",
      "generally\tgener\n",
      "more\tmore\n",
      "robust\trobust\n",
      "when\twhen\n",
      "given\tgiven\n",
      "unfamiliar\tunfamiliar\n",
      "input,\tinput,\n",
      "especially\tespeci\n",
      "input\tinput\n",
      "that\tthat\n",
      "contains\tcontain\n",
      "errors\terror\n",
      "(as\t(a\n",
      "is\tis\n",
      "very\tveri\n",
      "common\tcommon\n",
      "for\tfor\n",
      "real-world\treal-world\n",
      "data),\tdata),\n",
      "and\tand\n",
      "produce\tproduc\n",
      "more\tmore\n",
      "reliable\treliabl\n",
      "results\tresult\n",
      "when\twhen\n",
      "integrated\tintegr\n",
      "into\tinto\n",
      "a\ta\n",
      "larger\tlarger\n",
      "system\tsystem\n",
      "comprising\tcompris\n",
      "multiple\tmultipl\n",
      "subtasks.\tsubtasks.\n",
      "\n",
      "Many\tmani\n",
      "of\tof\n",
      "the\tthe\n",
      "notable\tnotabl\n",
      "early\tearli\n",
      "successes\tsuccess\n",
      "occurred\toccur\n",
      "in\tin\n",
      "the\tthe\n",
      "field\tfield\n",
      "of\tof\n",
      "machine\tmachin\n",
      "translation,\ttranslation,\n",
      "due\tdue\n",
      "especially\tespeci\n",
      "to\tto\n",
      "work\twork\n",
      "at\tat\n",
      "IBM\tibm\n",
      "Research,\tresearch,\n",
      "where\twhere\n",
      "successively\tsuccess\n",
      "more\tmore\n",
      "complicated\tcomplic\n",
      "statistical\tstatist\n",
      "models\tmodel\n",
      "were\twere\n",
      "developed.\tdeveloped.\n",
      "\n",
      "These\tthese\n",
      "systems\tsystem\n",
      "were\twere\n",
      "able\tabl\n",
      "to\tto\n",
      "take\ttake\n",
      "advantage\tadvantag\n",
      "of\tof\n",
      "existing\texist\n",
      "multilingual\tmultilingu\n",
      "textual\ttextual\n",
      "corpora\tcorpora\n",
      "that\tthat\n",
      "had\thad\n",
      "been\tbeen\n",
      "produced\tproduc\n",
      "by\tby\n",
      "the\tthe\n",
      "Parliament\tparliament\n",
      "of\tof\n",
      "Canada\tcanada\n",
      "and\tand\n",
      "the\tthe\n",
      "European\teuropean\n",
      "Union\tunion\n",
      "as\tas\n",
      "a\ta\n",
      "result\tresult\n",
      "of\tof\n",
      "laws\tlaw\n",
      "calling\tcall\n",
      "for\tfor\n",
      "the\tthe\n",
      "translation\ttranslat\n",
      "of\tof\n",
      "all\tall\n",
      "governmental\tgovernment\n",
      "proceedings\tproceed\n",
      "into\tinto\n",
      "all\tall\n",
      "official\toffici\n",
      "languages\tlanguag\n",
      "of\tof\n",
      "the\tthe\n",
      "corresponding\tcorrespond\n",
      "systems\tsystem\n",
      "of\tof\n",
      "government.\tgovernment.\n",
      "\n",
      "However,\thowever,\n",
      "most\tmost\n",
      "other\tother\n",
      "systems\tsystem\n",
      "depended\tdepend\n",
      "on\ton\n",
      "corpora\tcorpora\n",
      "specifically\tspecif\n",
      "developed\tdevelop\n",
      "for\tfor\n",
      "the\tthe\n",
      "tasks\ttask\n",
      "implemented\timplement\n",
      "by\tby\n",
      "these\tthese\n",
      "systems,\tsystems,\n",
      "which\twhich\n",
      "was\twa\n",
      "(and\t(and\n",
      "often\toften\n",
      "continues\tcontinu\n",
      "to\tto\n",
      "be)\tbe)\n",
      "a\ta\n",
      "major\tmajor\n",
      "limitation\tlimit\n",
      "in\tin\n",
      "the\tthe\n",
      "success\tsuccess\n",
      "of\tof\n",
      "these\tthese\n",
      "systems.\tsystems.\n",
      "\n",
      "As\tAs\n",
      "a\ta\n",
      "result,\tresult,\n",
      "a\ta\n",
      "great\tgreat\n",
      "deal\tdeal\n",
      "of\tof\n",
      "research\tresearch\n",
      "has\tha\n",
      "gone\tgone\n",
      "into\tinto\n",
      "methods\tmethod\n",
      "of\tof\n",
      "more\tmore\n",
      "effectively\teffect\n",
      "learning\tlearn\n",
      "from\tfrom\n",
      "limited\tlimit\n",
      "amounts\tamount\n",
      "of\tof\n",
      "data.\tdata.\n",
      "\n",
      "Recent\trecent\n",
      "research\tresearch\n",
      "has\tha\n",
      "increasingly\tincreasingli\n",
      "focused\tfocus\n",
      "on\ton\n",
      "unsupervised\tunsupervis\n",
      "and\tand\n",
      "semi-supervised\tsemi-supervis\n",
      "learning\tlearn\n",
      "algorithms.\talgorithms.\n",
      "\n",
      "Such\tsuch\n",
      "algorithms\talgorithm\n",
      "are\tare\n",
      "able\tabl\n",
      "to\tto\n",
      "learn\tlearn\n",
      "from\tfrom\n",
      "data\tdata\n",
      "that\tthat\n",
      "has\tha\n",
      "not\tnot\n",
      "been\tbeen\n",
      "hand-annotated\thand-annot\n",
      "with\twith\n",
      "the\tthe\n",
      "desired\tdesir\n",
      "answers,\tanswers,\n",
      "or\tor\n",
      "using\tuse\n",
      "a\ta\n",
      "combination\tcombin\n",
      "of\tof\n",
      "annotated\tannot\n",
      "and\tand\n",
      "non-annotated\tnon-annot\n",
      "data.\tdata.\n",
      "\n",
      "Generally,\tgenerally,\n",
      "this\tthi\n",
      "task\ttask\n",
      "is\tis\n",
      "much\tmuch\n",
      "more\tmore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficult\tdifficult\n",
      "than\tthan\n",
      "supervised\tsupervis\n",
      "learning,\tlearning,\n",
      "and\tand\n",
      "typically\ttypic\n",
      "produces\tproduc\n",
      "less\tless\n",
      "accurate\taccur\n",
      "results\tresult\n",
      "for\tfor\n",
      "a\ta\n",
      "given\tgiven\n",
      "amount\tamount\n",
      "of\tof\n",
      "input\tinput\n",
      "data.\tdata.\n",
      "\n",
      "However,\thowever,\n",
      "there\tthere\n",
      "is\tis\n",
      "an\tan\n",
      "enormous\tenorm\n",
      "amount\tamount\n",
      "of\tof\n",
      "non-annotated\tnon-annot\n",
      "data\tdata\n",
      "available\tavail\n",
      "(including,\t(including,\n",
      "among\tamong\n",
      "other\tother\n",
      "things,\tthings,\n",
      "the\tthe\n",
      "entire\tentir\n",
      "content\tcontent\n",
      "of\tof\n",
      "the\tthe\n",
      "World\tworld\n",
      "Wide\twide\n",
      "Web),\tweb),\n",
      "which\twhich\n",
      "can\tcan\n",
      "often\toften\n",
      "make\tmake\n",
      "up\tup\n",
      "for\tfor\n",
      "the\tthe\n",
      "inferior\tinferior\n",
      "results.\tresults.\n",
      "\n",
      "NLP\tnlp\n",
      "using\tuse\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "\n",
      "Modern\tmodern\n",
      "NLP\tnlp\n",
      "algorithms\talgorithm\n",
      "are\tare\n",
      "based\tbase\n",
      "on\ton\n",
      "machine\tmachin\n",
      "learning,\tlearning,\n",
      "especially\tespeci\n",
      "statistical\tstatist\n",
      "machine\tmachin\n",
      "learning.\tlearning.\n",
      "\n",
      "The\tthe\n",
      "paradigm\tparadigm\n",
      "of\tof\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "is\tis\n",
      "different\tdiffer\n",
      "from\tfrom\n",
      "that\tthat\n",
      "of\tof\n",
      "most\tmost\n",
      "prior\tprior\n",
      "attempts\tattempt\n",
      "at\tat\n",
      "language\tlanguag\n",
      "processing.\tprocessing.\n",
      "\n",
      "Prior\tprior\n",
      "implementations\timplement\n",
      "of\tof\n",
      "language-processing\tlanguage-process\n",
      "tasks\ttask\n",
      "typically\ttypic\n",
      "involved\tinvolv\n",
      "the\tthe\n",
      "direct\tdirect\n",
      "hand\thand\n",
      "coding\tcode\n",
      "of\tof\n",
      "large\tlarg\n",
      "sets\tset\n",
      "of\tof\n",
      "rules.\trules.\n",
      "\n",
      "The\tthe\n",
      "machine-learning\tmachine-learn\n",
      "paradigm\tparadigm\n",
      "calls\tcall\n",
      "instead\tinstead\n",
      "for\tfor\n",
      "using\tuse\n",
      "general\tgener\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "-\t-\n",
      "often,\toften,\n",
      "although\talthough\n",
      "not\tnot\n",
      "always,\talways,\n",
      "grounded\tground\n",
      "in\tin\n",
      "statistical\tstatist\n",
      "inference\tinfer\n",
      "-\t-\n",
      "to\tto\n",
      "automatically\tautomat\n",
      "learn\tlearn\n",
      "such\tsuch\n",
      "rules\trule\n",
      "through\tthrough\n",
      "the\tthe\n",
      "analysis\tanalysi\n",
      "of\tof\n",
      "large\tlarg\n",
      "corpora\tcorpora\n",
      "of\tof\n",
      "typical\ttypic\n",
      "real-world\treal-world\n",
      "examples.\texamples.\n",
      "\n",
      "A\tA\n",
      "corpus\tcorpu\n",
      "(plural,\t(plural,\n",
      "\"corpora\")\t\"corpora\")\n",
      "is\tis\n",
      "a\ta\n",
      "set\tset\n",
      "of\tof\n",
      "documents\tdocument\n",
      "(or\t(or\n",
      "sometimes,\tsometimes,\n",
      "individual\tindividu\n",
      "sentences)\tsentences)\n",
      "that\tthat\n",
      "have\thave\n",
      "been\tbeen\n",
      "hand-annotated\thand-annot\n",
      "with\twith\n",
      "the\tthe\n",
      "correct\tcorrect\n",
      "values\tvalu\n",
      "to\tto\n",
      "be\tbe\n",
      "learned.\tlearned.\n",
      "\n",
      "Many\tmani\n",
      "different\tdiffer\n",
      "classes\tclass\n",
      "of\tof\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "have\thave\n",
      "been\tbeen\n",
      "applied\tappli\n",
      "to\tto\n",
      "NLP\tnlp\n",
      "tasks.\ttasks.\n",
      "\n",
      "These\tthese\n",
      "algorithms\talgorithm\n",
      "take\ttake\n",
      "as\tas\n",
      "input\tinput\n",
      "a\ta\n",
      "large\tlarg\n",
      "set\tset\n",
      "of\tof\n",
      "\"features\"\t\"features\"\n",
      "that\tthat\n",
      "are\tare\n",
      "generated\tgener\n",
      "from\tfrom\n",
      "the\tthe\n",
      "input\tinput\n",
      "data.\tdata.\n",
      "\n",
      "Some\tsome\n",
      "of\tof\n",
      "the\tthe\n",
      "earliest-used\tearliest-us\n",
      "algorithms,\talgorithms,\n",
      "such\tsuch\n",
      "as\tas\n",
      "decision\tdecis\n",
      "trees,\ttrees,\n",
      "produced\tproduc\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hard\thard\n",
      "if-then\tif-then\n",
      "rules\trule\n",
      "similar\tsimilar\n",
      "to\tto\n",
      "the\tthe\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "that\tthat\n",
      "were\twere\n",
      "then\tthen\n",
      "common.\tcommon.\n",
      "\n",
      "Increasingly,\tincreasingly,\n",
      "however,\thowever,\n",
      "research\tresearch\n",
      "has\tha\n",
      "focused\tfocus\n",
      "on\ton\n",
      "statistical\tstatist\n",
      "models,\tmodels,\n",
      "which\twhich\n",
      "make\tmake\n",
      "soft,\tsoft,\n",
      "probabilistic\tprobabilist\n",
      "decisions\tdecis\n",
      "based\tbase\n",
      "on\ton\n",
      "attaching\tattach\n",
      "real-valued\treal-valu\n",
      "weights\tweight\n",
      "to\tto\n",
      "each\teach\n",
      "input\tinput\n",
      "feature.\tfeature.\n",
      "\n",
      "Such\tsuch\n",
      "models\tmodel\n",
      "have\thave\n",
      "the\tthe\n",
      "advantage\tadvantag\n",
      "that\tthat\n",
      "they\tthey\n",
      "can\tcan\n",
      "express\texpress\n",
      "the\tthe\n",
      "relative\trel\n",
      "certainty\tcertainti\n",
      "of\tof\n",
      "many\tmani\n",
      "different\tdiffer\n",
      "possible\tpossibl\n",
      "answers\tanswer\n",
      "rather\trather\n",
      "than\tthan\n",
      "only\tonli\n",
      "one,\tone,\n",
      "producing\tproduc\n",
      "more\tmore\n",
      "reliable\treliabl\n",
      "results\tresult\n",
      "when\twhen\n",
      "such\tsuch\n",
      "a\ta\n",
      "model\tmodel\n",
      "is\tis\n",
      "included\tinclud\n",
      "as\tas\n",
      "a\ta\n",
      "component\tcompon\n",
      "of\tof\n",
      "a\ta\n",
      "larger\tlarger\n",
      "system.\tsystem.\n",
      "\n",
      "Systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "machine-learning\tmachine-learn\n",
      "algorithms\talgorithm\n",
      "have\thave\n",
      "many\tmani\n",
      "advantages\tadvantag\n",
      "over\tover\n",
      "hand-produced\thand-produc\n",
      "rules:\trules:\n",
      "\n",
      "The\tthe\n",
      "learning\tlearn\n",
      "procedures\tprocedur\n",
      "used\tuse\n",
      "during\tdure\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "automatically\tautomat\n",
      "focus\tfocu\n",
      "on\ton\n",
      "the\tthe\n",
      "most\tmost\n",
      "common\tcommon\n",
      "cases,\tcases,\n",
      "whereas\twherea\n",
      "when\twhen\n",
      "writing\twrite\n",
      "rules\trule\n",
      "by\tby\n",
      "hand\thand\n",
      "it\tit\n",
      "is\tis\n",
      "often\toften\n",
      "not\tnot\n",
      "obvious\tobviou\n",
      "at\tat\n",
      "all\tall\n",
      "where\twhere\n",
      "the\tthe\n",
      "effort\teffort\n",
      "should\tshould\n",
      "be\tbe\n",
      "directed.\tdirected.\n",
      "\n",
      "Automatic\tautomat\n",
      "learning\tlearn\n",
      "procedures\tprocedur\n",
      "can\tcan\n",
      "make\tmake\n",
      "use\tuse\n",
      "of\tof\n",
      "statistical\tstatist\n",
      "inference\tinfer\n",
      "algorithms\talgorithm\n",
      "to\tto\n",
      "produce\tproduc\n",
      "models\tmodel\n",
      "that\tthat\n",
      "are\tare\n",
      "robust\trobust\n",
      "to\tto\n",
      "unfamiliar\tunfamiliar\n",
      "input\tinput\n",
      "(e.g.\t(e.g.\n",
      "containing\tcontain\n",
      "words\tword\n",
      "or\tor\n",
      "structures\tstructur\n",
      "that\tthat\n",
      "have\thave\n",
      "not\tnot\n",
      "been\tbeen\n",
      "seen\tseen\n",
      "before)\tbefore)\n",
      "and\tand\n",
      "to\tto\n",
      "erroneous\terron\n",
      "input\tinput\n",
      "(e.g.\t(e.g.\n",
      "with\twith\n",
      "misspelled\tmisspel\n",
      "words\tword\n",
      "or\tor\n",
      "words\tword\n",
      "accidentally\taccident\n",
      "omitted).\tomitted).\n",
      "\n",
      "Generally,\tgenerally,\n",
      "handling\thandl\n",
      "such\tsuch\n",
      "input\tinput\n",
      "gracefully\tgrace\n",
      "with\twith\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "--\t--\n",
      "or\tor\n",
      "more\tmore\n",
      "generally,\tgenerally,\n",
      "creating\tcreat\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "that\tthat\n",
      "make\tmake\n",
      "soft\tsoft\n",
      "decisions\tdecis\n",
      "--\t--\n",
      "extremely\textrem\n",
      "difficult,\tdifficult,\n",
      "error-prone\terror-pron\n",
      "and\tand\n",
      "time-consuming.\ttime-consuming.\n",
      "\n",
      "Systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "automatically\tautomat\n",
      "learning\tlearn\n",
      "the\tthe\n",
      "rules\trule\n",
      "can\tcan\n",
      "be\tbe\n",
      "made\tmade\n",
      "more\tmore\n",
      "accurate\taccur\n",
      "simply\tsimpli\n",
      "by\tby\n",
      "supplying\tsuppli\n",
      "more\tmore\n",
      "input\tinput\n",
      "data.\tdata.\n",
      "\n",
      "However,\thowever,\n",
      "systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "can\tcan\n",
      "only\tonli\n",
      "be\tbe\n",
      "made\tmade\n",
      "more\tmore\n",
      "accurate\taccur\n",
      "by\tby\n",
      "increasing\tincreas\n",
      "the\tthe\n",
      "complexity\tcomplex\n",
      "of\tof\n",
      "the\tthe\n",
      "rules,\trules,\n",
      "which\twhich\n",
      "is\tis\n",
      "a\ta\n",
      "much\tmuch\n",
      "more\tmore\n",
      "difficult\tdifficult\n",
      "task.\ttask.\n",
      "\n",
      "In\tIn\n",
      "particular,\tparticular,\n",
      "there\tthere\n",
      "is\tis\n",
      "a\ta\n",
      "limit\tlimit\n",
      "to\tto\n",
      "the\tthe\n",
      "complexity\tcomplex\n",
      "of\tof\n",
      "systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "hand-crafted\thand-craft\n",
      "rules,\trules,\n",
      "beyond\tbeyond\n",
      "which\twhich\n",
      "the\tthe\n",
      "systems\tsystem\n",
      "become\tbecom\n",
      "more\tmore\n",
      "and\tand\n",
      "more\tmore\n",
      "unmanageable.\tunmanageable.\n",
      "\n",
      "However,\thowever,\n",
      "creating\tcreat\n",
      "more\tmore\n",
      "data\tdata\n",
      "to\tto\n",
      "input\tinput\n",
      "to\tto\n",
      "machine-learning\tmachine-learn\n",
      "systems\tsystem\n",
      "simply\tsimpli\n",
      "requires\trequir\n",
      "a\ta\n",
      "corresponding\tcorrespond\n",
      "increase\tincreas\n",
      "in\tin\n",
      "the\tthe\n",
      "number\tnumber\n",
      "of\tof\n",
      "man-hours\tman-hour\n",
      "worked,\tworked,\n",
      "generally\tgener\n",
      "without\twithout\n",
      "significant\tsignific\n",
      "increases\tincreas\n",
      "in\tin\n",
      "the\tthe\n",
      "complexity\tcomplex\n",
      "of\tof\n",
      "the\tthe\n",
      "annotation\tannot\n",
      "process.\tprocess.\n",
      "\n",
      "The\tthe\n",
      "subfield\tsubfield\n",
      "of\tof\n",
      "NLP\tnlp\n",
      "devoted\tdevot\n",
      "to\tto\n",
      "learning\tlearn\n",
      "approaches\tapproach\n",
      "is\tis\n",
      "known\tknown\n",
      "as\tas\n",
      "Natural\tnatur\n",
      "Language\tlanguag\n",
      "Learning\tlearn\n",
      "(NLL)\t(nll)\n",
      "and\tand\n",
      "its\tit\n",
      "conference\tconfer\n",
      "CoNLL\tconll\n",
      "and\tand\n",
      "peak\tpeak\n",
      "body\tbodi\n",
      "SIGNLL\tsignll\n",
      "are\tare\n",
      "sponsored\tsponsor\n",
      "by\tby\n",
      "ACL,\tacl,\n",
      "recognizing\trecogn\n",
      "also\talso\n",
      "their\ttheir\n",
      "links\tlink\n",
      "with\twith\n",
      "Computational\tcomput\n",
      "Linguistics\tlinguist\n",
      "and\tand\n",
      "Language\tlanguag\n",
      "Acquisition.\tacquisition.\n",
      "\n",
      "When\twhen\n",
      "the\tthe\n",
      "aims\taim\n",
      "of\tof\n",
      "computational\tcomput\n",
      "language\tlanguag\n",
      "learning\tlearn\n",
      "research\tresearch\n",
      "is\tis\n",
      "to\tto\n",
      "understand\tunderstand\n",
      "more\tmore\n",
      "about\tabout\n",
      "human\thuman\n",
      "language\tlanguag\n",
      "acquisition,\tacquisition,\n",
      "or\tor\n",
      "psycholinguistics,\tpsycholinguistics,\n",
      "NLL\tnll\n",
      "overlaps\toverlap\n",
      "into\tinto\n",
      "the\tthe\n",
      "related\trelat\n",
      "field\tfield\n",
      "of\tof\n",
      "Computational\tcomput\n",
      "Psycholinguistics.\tpsycholinguistics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        args = (word, PorterStemmer().stem(word))\n",
    "        print(\"%s\\t%s\" % args)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53. Tokenization\n",
    "[Stanford Core NLP](http://nlp.stanford.edu/software/corenlp.shtml)を用い，入力テキストの解析結果をXML形式で得よ．また，このXMLファイルを読み込み，入力テキストを1行1単語の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -mx5g -cp \"stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,coref -file ../Corpus/nlp.txt -outputFormat xml -outputDirectory Output\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [2.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [4.3 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580704 unique entries out of 581863 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4869 unique entries out of 4869 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585573 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n",
      "[main] INFO edu.stanford.nlp.coref.statistical.SimpleLinearClassifier - Loading coref model edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz ... done [0.8 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency\n",
      "\n",
      "Processing file /home/ke1dy/PracticeNLP100Knocks2015/Chapter6/../Corpus/nlp.txt ... writing to /home/ke1dy/PracticeNLP100Knocks2015/Chapter6/Output/nlp.txt.xml\n",
      "Annotating file /home/ke1dy/PracticeNLP100Knocks2015/Chapter6/../Corpus/nlp.txt ... done [39.6 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "POSTaggerAnnotator: 0.5 sec.\n",
      "MorphaAnnotator: 0.2 sec.\n",
      "NERCombinerAnnotator: 8.6 sec.\n",
      "ParserAnnotator: 17.3 sec.\n",
      "CorefAnnotator: 12.9 sec.\n",
      "TOTAL: 39.6 sec. for 1452 tokens at 36.7 tokens/sec.\n",
      "Pipeline setup: 57.3 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 97.4 sec.\n"
     ]
    }
   ],
   "source": [
    "!stanford-corenlp-full-2018-10-05/corenlp.sh -annotators tokenize,ssplit,pos,lemma,ner,parse,coref -file ../Corpus/nlp.txt -outputFormat xml -outputDirectory Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp.txt.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.parse(\"Output/nlp.txt.xml\").getroot()\n",
    "\n",
    "sentences_nlp = []\n",
    "for sentence_tag in root.iter(\"sentence\"):\n",
    "    sentence_nlp = []\n",
    "    for word_tag in sentence_tag.iter(\"word\"):\n",
    "        sentence_nlp.append(word_tag.text)\n",
    "    sentences_nlp.append(sentence_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "From\n",
      "Wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "-LRB-\n",
      "NLP\n",
      "-RRB-\n",
      "is\n",
      "a\n",
      "field\n",
      "of\n",
      "computer\n",
      "science\n",
      ",\n",
      "artificial\n",
      "intelligence\n",
      ",\n",
      "and\n",
      "linguistics\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interactions\n",
      "between\n",
      "computers\n",
      "and\n",
      "human\n",
      "-LRB-\n",
      "natural\n",
      "-RRB-\n",
      "languages\n",
      ".\n",
      "As\n",
      "such\n",
      ",\n",
      "NLP\n",
      "is\n",
      "related\n",
      "to\n",
      "the\n",
      "area\n",
      "of\n",
      "humani-computer\n",
      "interaction\n",
      ".\n",
      "Many\n",
      "challenges\n",
      "in\n",
      "NLP\n",
      "involve\n",
      "natural\n",
      "language\n",
      "understanding\n",
      ",\n",
      "that\n",
      "is\n",
      ",\n",
      "enabling\n",
      "computers\n",
      "to\n",
      "derive\n",
      "meaning\n",
      "from\n",
      "human\n",
      "or\n",
      "natural\n",
      "language\n",
      "input\n",
      ",\n",
      "and\n",
      "others\n",
      "involve\n",
      "natural\n",
      "language\n",
      "generation\n",
      ".\n",
      "History\n",
      "The\n",
      "history\n",
      "of\n",
      "NLP\n",
      "generally\n",
      "starts\n",
      "in\n",
      "the\n",
      "1950s\n",
      ",\n",
      "although\n",
      "work\n",
      "can\n",
      "be\n",
      "found\n",
      "from\n",
      "earlier\n",
      "periods\n",
      ".\n",
      "In\n",
      "1950\n",
      ",\n",
      "Alan\n",
      "Turing\n",
      "published\n",
      "an\n",
      "article\n",
      "titled\n",
      "``\n",
      "Computing\n",
      "Machinery\n",
      "and\n",
      "Intelligence\n",
      "''\n",
      "which\n",
      "proposed\n",
      "what\n",
      "is\n",
      "now\n",
      "called\n",
      "the\n",
      "Turing\n",
      "test\n",
      "as\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intelligence\n",
      ".\n",
      "The\n",
      "Georgetown\n",
      "experiment\n",
      "in\n",
      "1954\n",
      "involved\n",
      "fully\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "more\n",
      "than\n",
      "sixty\n",
      "Russian\n",
      "sentences\n",
      "into\n",
      "English\n",
      ".\n",
      "The\n",
      "authors\n",
      "claimed\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "years\n",
      ",\n",
      "machine\n",
      "translation\n",
      "would\n",
      "be\n",
      "a\n",
      "solved\n",
      "problem\n",
      ".\n",
      "However\n",
      ",\n",
      "real\n",
      "progress\n",
      "was\n",
      "much\n",
      "slower\n",
      ",\n",
      "and\n",
      "after\n",
      "the\n",
      "ALPAC\n",
      "report\n",
      "in\n",
      "1966\n",
      ",\n",
      "which\n",
      "found\n",
      "that\n",
      "ten\n",
      "year\n",
      "long\n",
      "research\n",
      "had\n",
      "failed\n",
      "to\n",
      "fulfill\n",
      "the\n",
      "expectations\n",
      ",\n",
      "funding\n",
      "for\n",
      "machine\n",
      "translation\n",
      "was\n",
      "dramatically\n",
      "reduced\n",
      ".\n",
      "Little\n",
      "further\n",
      "research\n",
      "in\n",
      "machine\n",
      "translation\n",
      "was\n",
      "conducted\n",
      "until\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "when\n",
      "the\n",
      "first\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "systems\n",
      "were\n",
      "developed\n",
      ".\n",
      "Some\n",
      "notably\n",
      "successful\n",
      "NLP\n",
      "systems\n",
      "developed\n",
      "in\n",
      "the\n",
      "1960s\n",
      "were\n",
      "SHRDLU\n",
      ",\n",
      "a\n",
      "natural\n",
      "language\n",
      "system\n",
      "working\n",
      "in\n",
      "restricted\n",
      "``\n",
      "blocks\n",
      "worlds\n",
      "''\n",
      "with\n",
      "restricted\n",
      "vocabularies\n",
      ",\n",
      "and\n",
      "ELIZA\n",
      ",\n",
      "a\n",
      "simulation\n",
      "of\n",
      "a\n",
      "Rogerian\n",
      "psychotherapist\n",
      ",\n",
      "written\n",
      "by\n",
      "Joseph\n",
      "Weizenbaum\n",
      "between\n",
      "1964\n",
      "to\n",
      "1966\n",
      ".\n",
      "Using\n",
      "almost\n",
      "no\n",
      "information\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emotion\n",
      ",\n",
      "ELIZA\n",
      "sometimes\n",
      "provided\n",
      "a\n",
      "startlingly\n",
      "human-like\n",
      "interaction\n",
      ".\n",
      "When\n",
      "the\n",
      "``\n",
      "patient\n",
      "''\n",
      "exceeded\n",
      "the\n",
      "very\n",
      "small\n",
      "knowledge\n",
      "base\n",
      ",\n",
      "ELIZA\n",
      "might\n",
      "provide\n",
      "a\n",
      "generic\n",
      "response\n",
      ",\n",
      "for\n",
      "example\n",
      ",\n",
      "responding\n",
      "to\n",
      "``\n",
      "My\n",
      "head\n",
      "hurts\n",
      "''\n",
      "with\n",
      "``\n",
      "Why\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurts\n",
      "?\n",
      "''\n",
      ".\n",
      "During\n",
      "the\n",
      "1970s\n",
      "many\n",
      "programmers\n",
      "began\n",
      "to\n",
      "write\n",
      "`\n",
      "conceptual\n",
      "ontologies\n",
      "'\n",
      ",\n",
      "which\n",
      "structured\n",
      "real-world\n",
      "information\n",
      "into\n",
      "computer-understandable\n",
      "data\n",
      ".\n",
      "Examples\n",
      "are\n",
      "MARGIE\n",
      "-LRB-\n",
      "Schank\n",
      ",\n",
      "1975\n",
      "-RRB-\n",
      ",\n",
      "SAM\n",
      "-LRB-\n",
      "Cullingford\n",
      ",\n",
      "1978\n",
      "-RRB-\n",
      ",\n",
      "PAM\n",
      "-LRB-\n",
      "Wilensky\n",
      ",\n",
      "1978\n",
      "-RRB-\n",
      ",\n",
      "TaleSpin\n",
      "-LRB-\n",
      "Meehan\n",
      ",\n",
      "1976\n",
      "-RRB-\n",
      ",\n",
      "QUALM\n",
      "-LRB-\n",
      "Lehnert\n",
      ",\n",
      "1977\n",
      "-RRB-\n",
      ",\n",
      "Politics\n",
      "-LRB-\n",
      "Carbonell\n",
      ",\n",
      "1979\n",
      "-RRB-\n",
      ",\n",
      "and\n",
      "Plot\n",
      "Units\n",
      "-LRB-\n",
      "Lehnert\n",
      "1981\n",
      "-RRB-\n",
      ".\n",
      "During\n",
      "this\n",
      "time\n",
      ",\n",
      "many\n",
      "chatterbots\n",
      "were\n",
      "written\n",
      "including\n",
      "PARRY\n",
      ",\n",
      "Racter\n",
      ",\n",
      "and\n",
      "Jabberwacky\n",
      ".\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "NLP\n",
      "systems\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "sets\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      ".\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "however\n",
      ",\n",
      "there\n",
      "was\n",
      "a\n",
      "revolution\n",
      "in\n",
      "NLP\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "for\n",
      "language\n",
      "processing\n",
      ".\n",
      "This\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "resulting\n",
      "from\n",
      "Moore\n",
      "'s\n",
      "Law\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theories\n",
      "of\n",
      "linguistics\n",
      "-LRB-\n",
      "e.g.\n",
      "transformational\n",
      "grammar\n",
      "-RRB-\n",
      ",\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      ",\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      ",\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "existing\n",
      "hand-written\n",
      "rules\n",
      ".\n",
      "However\n",
      ",\n",
      "Part\n",
      "of\n",
      "speech\n",
      "tagging\n",
      "introduced\n",
      "the\n",
      "use\n",
      "of\n",
      "Hidden\n",
      "Markov\n",
      "Models\n",
      "to\n",
      "NLP\n",
      ",\n",
      "and\n",
      "increasingly\n",
      ",\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "the\n",
      "features\n",
      "making\n",
      "up\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "The\n",
      "cache\n",
      "language\n",
      "models\n",
      "upon\n",
      "which\n",
      "many\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "now\n",
      "rely\n",
      "are\n",
      "examples\n",
      "of\n",
      "such\n",
      "statistical\n",
      "models\n",
      ".\n",
      "Such\n",
      "models\n",
      "are\n",
      "generally\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input\n",
      ",\n",
      "especially\n",
      "input\n",
      "that\n",
      "contains\n",
      "errors\n",
      "-LRB-\n",
      "as\n",
      "is\n",
      "very\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data\n",
      "-RRB-\n",
      ",\n",
      "and\n",
      "produce\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "integrated\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "comprising\n",
      "multiple\n",
      "subtasks\n",
      ".\n",
      "Many\n",
      "of\n",
      "the\n",
      "notable\n",
      "early\n",
      "successes\n",
      "occurred\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machine\n",
      "translation\n",
      ",\n",
      "due\n",
      "especially\n",
      "to\n",
      "work\n",
      "at\n",
      "IBM\n",
      "Research\n",
      ",\n",
      "where\n",
      "successively\n",
      "more\n",
      "complicated\n",
      "statistical\n",
      "models\n",
      "were\n",
      "developed\n",
      ".\n",
      "These\n",
      "systems\n",
      "were\n",
      "able\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "existing\n",
      "multilingual\n",
      "textual\n",
      "corpora\n",
      "that\n",
      "had\n",
      "been\n",
      "produced\n",
      "by\n",
      "the\n",
      "Parliament\n",
      "of\n",
      "Canada\n",
      "and\n",
      "the\n",
      "European\n",
      "Union\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "laws\n",
      "calling\n",
      "for\n",
      "the\n",
      "translation\n",
      "of\n",
      "all\n",
      "governmental\n",
      "proceedings\n",
      "into\n",
      "all\n",
      "official\n",
      "languages\n",
      "of\n",
      "the\n",
      "corresponding\n",
      "systems\n",
      "of\n",
      "government\n",
      ".\n",
      "However\n",
      ",\n",
      "most\n",
      "other\n",
      "systems\n",
      "depended\n",
      "on\n",
      "corpora\n",
      "specifically\n",
      "developed\n",
      "for\n",
      "the\n",
      "tasks\n",
      "implemented\n",
      "by\n",
      "these\n",
      "systems\n",
      ",\n",
      "which\n",
      "was\n",
      "-LRB-\n",
      "and\n",
      "often\n",
      "continues\n",
      "to\n",
      "be\n",
      "-RRB-\n",
      "a\n",
      "major\n",
      "limitation\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "systems\n",
      ".\n",
      "As\n",
      "a\n",
      "result\n",
      ",\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "has\n",
      "gone\n",
      "into\n",
      "methods\n",
      "of\n",
      "more\n",
      "effectively\n",
      "learning\n",
      "from\n",
      "limited\n",
      "amounts\n",
      "of\n",
      "data\n",
      ".\n",
      "Recent\n",
      "research\n",
      "has\n",
      "increasingly\n",
      "focused\n",
      "on\n",
      "unsupervised\n",
      "and\n",
      "semi-supervised\n",
      "learning\n",
      "algorithms\n",
      ".\n",
      "Such\n",
      "algorithms\n",
      "are\n",
      "able\n",
      "to\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "has\n",
      "not\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "desired\n",
      "answers\n",
      ",\n",
      "or\n",
      "using\n",
      "a\n",
      "combination\n",
      "of\n",
      "annotated\n",
      "and\n",
      "non-annotated\n",
      "data\n",
      ".\n",
      "Generally\n",
      ",\n",
      "this\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervised\n",
      "learning\n",
      ",\n",
      "and\n",
      "typically\n",
      "produces\n",
      "less\n",
      "accurate\n",
      "results\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "there\n",
      "is\n",
      "an\n",
      "enormous\n",
      "amount\n",
      "of\n",
      "non-annotated\n",
      "data\n",
      "available\n",
      "-LRB-\n",
      "including\n",
      ",\n",
      "among\n",
      "other\n",
      "things\n",
      ",\n",
      "the\n",
      "entire\n",
      "content\n",
      "of\n",
      "the\n",
      "World\n",
      "Wide\n",
      "Web\n",
      "-RRB-\n",
      ",\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "results\n",
      ".\n",
      "NLP\n",
      "using\n",
      "machine\n",
      "learning\n",
      "Modern\n",
      "NLP\n",
      "algorithms\n",
      "are\n",
      "based\n",
      "on\n",
      "machine\n",
      "learning\n",
      ",\n",
      "especially\n",
      "statistical\n",
      "machine\n",
      "learning\n",
      ".\n",
      "The\n",
      "paradigm\n",
      "of\n",
      "machine\n",
      "learning\n",
      "is\n",
      "different\n",
      "from\n",
      "that\n",
      "of\n",
      "most\n",
      "prior\n",
      "attempts\n",
      "at\n",
      "language\n",
      "processing\n",
      ".\n",
      "Prior\n",
      "implementations\n",
      "of\n",
      "language-processing\n",
      "tasks\n",
      "typically\n",
      "involved\n",
      "the\n",
      "direct\n",
      "hand\n",
      "coding\n",
      "of\n",
      "large\n",
      "sets\n",
      "of\n",
      "rules\n",
      ".\n",
      "The\n",
      "machine-learning\n",
      "paradigm\n",
      "calls\n",
      "instead\n",
      "for\n",
      "using\n",
      "general\n",
      "learning\n",
      "algorithms\n",
      "-\n",
      "often\n",
      ",\n",
      "although\n",
      "not\n",
      "always\n",
      ",\n",
      "grounded\n",
      "in\n",
      "statistical\n",
      "inference\n",
      "-\n",
      "to\n",
      "automatically\n",
      "learn\n",
      "such\n",
      "rules\n",
      "through\n",
      "the\n",
      "analysis\n",
      "of\n",
      "large\n",
      "corpora\n",
      "of\n",
      "typical\n",
      "real-world\n",
      "examples\n",
      ".\n",
      "A\n",
      "corpus\n",
      "-LRB-\n",
      "plural\n",
      ",\n",
      "``\n",
      "corpora\n",
      "''\n",
      "-RRB-\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "documents\n",
      "-LRB-\n",
      "or\n",
      "sometimes\n",
      ",\n",
      "individual\n",
      "sentences\n",
      "-RRB-\n",
      "that\n",
      "have\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "correct\n",
      "values\n",
      "to\n",
      "be\n",
      "learned\n",
      ".\n",
      "Many\n",
      "different\n",
      "classes\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "have\n",
      "been\n",
      "applied\n",
      "to\n",
      "NLP\n",
      "tasks\n",
      ".\n",
      "These\n",
      "algorithms\n",
      "take\n",
      "as\n",
      "input\n",
      "a\n",
      "large\n",
      "set\n",
      "of\n",
      "``\n",
      "features\n",
      "''\n",
      "that\n",
      "are\n",
      "generated\n",
      "from\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "algorithms\n",
      ",\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      ",\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "the\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "were\n",
      "then\n",
      "common\n",
      ".\n",
      "Increasingly\n",
      ",\n",
      "however\n",
      ",\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "each\n",
      "input\n",
      "feature\n",
      ".\n",
      "Such\n",
      "models\n",
      "have\n",
      "the\n",
      "advantage\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "relative\n",
      "certainty\n",
      "of\n",
      "many\n",
      "different\n",
      "possible\n",
      "answers\n",
      "rather\n",
      "than\n",
      "only\n",
      "one\n",
      ",\n",
      "producing\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "included\n",
      "as\n",
      "a\n",
      "component\n",
      "of\n",
      "a\n",
      "larger\n",
      "system\n",
      ".\n",
      "Systems\n",
      "based\n",
      "on\n",
      "machine-learning\n",
      "algorithms\n",
      "have\n",
      "many\n",
      "advantages\n",
      "over\n",
      "hand-produced\n",
      "rules\n",
      ":\n",
      "The\n",
      "learning\n",
      "procedures\n",
      "used\n",
      "during\n",
      "machine\n",
      "learning\n",
      "automatically\n",
      "focus\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "cases\n",
      ",\n",
      "whereas\n",
      "when\n",
      "writing\n",
      "rules\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "obvious\n",
      "at\n",
      "all\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "directed\n",
      ".\n",
      "Automatic\n",
      "learning\n",
      "procedures\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statistical\n",
      "inference\n",
      "algorithms\n",
      "to\n",
      "produce\n",
      "models\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "-LRB-\n",
      "e.g.\n",
      "containing\n",
      "words\n",
      "or\n",
      "structures\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "before\n",
      "-RRB-\n",
      "and\n",
      "to\n",
      "erroneous\n",
      "input\n",
      "-LRB-\n",
      "e.g.\n",
      "with\n",
      "misspelled\n",
      "words\n",
      "or\n",
      "words\n",
      "accidentally\n",
      "omitted\n",
      "-RRB-\n",
      ".\n",
      "Generally\n",
      ",\n",
      "handling\n",
      "such\n",
      "input\n",
      "gracefully\n",
      "with\n",
      "hand-written\n",
      "rules\n",
      "--\n",
      "or\n",
      "more\n",
      "generally\n",
      ",\n",
      "creating\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "make\n",
      "soft\n",
      "decisions\n",
      "--\n",
      "extremely\n",
      "difficult\n",
      ",\n",
      "error-prone\n",
      "and\n",
      "time-consuming\n",
      ".\n",
      "Systems\n",
      "based\n",
      "on\n",
      "automatically\n",
      "learning\n",
      "the\n",
      "rules\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "simply\n",
      "by\n",
      "supplying\n",
      "more\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-written\n",
      "rules\n",
      "can\n",
      "only\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "by\n",
      "increasing\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "rules\n",
      ",\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task\n",
      ".\n",
      "In\n",
      "particular\n",
      ",\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complexity\n",
      "of\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-crafted\n",
      "rules\n",
      ",\n",
      "beyond\n",
      "which\n",
      "the\n",
      "systems\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanageable\n",
      ".\n",
      "However\n",
      ",\n",
      "creating\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learning\n",
      "systems\n",
      "simply\n",
      "requires\n",
      "a\n",
      "corresponding\n",
      "increase\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hours\n",
      "worked\n",
      ",\n",
      "generally\n",
      "without\n",
      "significant\n",
      "increases\n",
      "in\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "annotation\n",
      "process\n",
      ".\n",
      "The\n",
      "subfield\n",
      "of\n",
      "NLP\n",
      "devoted\n",
      "to\n",
      "learning\n",
      "approaches\n",
      "is\n",
      "known\n",
      "as\n",
      "Natural\n",
      "Language\n",
      "Learning\n",
      "-LRB-\n",
      "NLL\n",
      "-RRB-\n",
      "and\n",
      "its\n",
      "conference\n",
      "CoNLL\n",
      "and\n",
      "peak\n",
      "body\n",
      "SIGNLL\n",
      "are\n",
      "sponsored\n",
      "by\n",
      "ACL\n",
      ",\n",
      "recognizing\n",
      "also\n",
      "their\n",
      "links\n",
      "with\n",
      "Computational\n",
      "Linguistics\n",
      "and\n",
      "Language\n",
      "Acquisition\n",
      ".\n",
      "When\n",
      "the\n",
      "aims\n",
      "of\n",
      "computational\n",
      "language\n",
      "learning\n",
      "research\n",
      "is\n",
      "to\n",
      "understand\n",
      "more\n",
      "about\n",
      "human\n",
      "language\n",
      "acquisition\n",
      ",\n",
      "or\n",
      "psycholinguistics\n",
      ",\n",
      "NLL\n",
      "overlaps\n",
      "into\n",
      "the\n",
      "related\n",
      "field\n",
      "of\n",
      "Computational\n",
      "Psycholinguistics\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sentence_nlp in sentences_nlp:\n",
    "    for word in sentence_nlp:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54. 品詞タグ付け\n",
    "Stanford Core NLPの解析結果XMLを読み込み，単語，レンマ，品詞をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      "From\tfrom\tIN\n",
      "Wikipedia\tWikipedia\tNNP\n",
      ",\t,\t,\n",
      "the\tthe\tDT\n",
      "free\tfree\tJJ\n",
      "encyclopedia\tencyclopedia\tNN\n",
      "Natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "NLP\tnlp\tNN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "field\tfield\tNN\n",
      "of\tof\tIN\n",
      "computer\tcomputer\tNN\n",
      "science\tscience\tNN\n",
      ",\t,\t,\n",
      "artificial\tartificial\tJJ\n",
      "intelligence\tintelligence\tNN\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "linguistics\tlinguistics\tNNS\n",
      "concerned\tconcern\tVBN\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "interactions\tinteraction\tNNS\n",
      "between\tbetween\tIN\n",
      "computers\tcomputer\tNNS\n",
      "and\tand\tCC\n",
      "human\thuman\tJJ\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "natural\tnatural\tJJ\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "languages\tlanguage\tNNS\n",
      ".\t.\t.\n",
      "As\tas\tIN\n",
      "such\tsuch\tJJ\n",
      ",\t,\t,\n",
      "NLP\tnlp\tNN\n",
      "is\tbe\tVBZ\n",
      "related\trelate\tVBN\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "area\tarea\tNN\n",
      "of\tof\tIN\n",
      "humani-computer\thumani-computer\tJJ\n",
      "interaction\tinteraction\tNN\n",
      ".\t.\t.\n",
      "Many\tmany\tJJ\n",
      "challenges\tchallenge\tNNS\n",
      "in\tin\tIN\n",
      "NLP\tnlp\tNN\n",
      "involve\tinvolve\tVBP\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "understanding\tunderstanding\tNN\n",
      ",\t,\t,\n",
      "that\tthat\tWDT\n",
      "is\tbe\tVBZ\n",
      ",\t,\t,\n",
      "enabling\tenable\tVBG\n",
      "computers\tcomputer\tNNS\n",
      "to\tto\tTO\n",
      "derive\tderive\tVB\n",
      "meaning\tmeaning\tNN\n",
      "from\tfrom\tIN\n",
      "human\thuman\tJJ\n",
      "or\tor\tCC\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "input\tinput\tNN\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "others\tother\tNNS\n",
      "involve\tinvolve\tVBP\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "generation\tgeneration\tNN\n",
      ".\t.\t.\n",
      "History\thistory\tNN\n",
      "The\tthe\tDT\n",
      "history\thistory\tNN\n",
      "of\tof\tIN\n",
      "NLP\tNLP\tNNP\n",
      "generally\tgenerally\tRB\n",
      "starts\tstart\tVBZ\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "1950s\t1950s\tCD\n",
      ",\t,\t,\n",
      "although\talthough\tIN\n",
      "work\twork\tNN\n",
      "can\tcan\tMD\n",
      "be\tbe\tVB\n",
      "found\tfind\tVBN\n",
      "from\tfrom\tIN\n",
      "earlier\tearlier\tJJR\n",
      "periods\tperiod\tNNS\n",
      ".\t.\t.\n",
      "In\tin\tIN\n",
      "1950\t1950\tCD\n",
      ",\t,\t,\n",
      "Alan\tAlan\tNNP\n",
      "Turing\tTuring\tNNP\n",
      "published\tpublish\tVBD\n",
      "an\ta\tDT\n",
      "article\tarticle\tNN\n",
      "titled\ttitle\tVBN\n",
      "``\t``\t``\n",
      "Computing\tComputing\tNNP\n",
      "Machinery\tMachinery\tNNP\n",
      "and\tand\tCC\n",
      "Intelligence\tIntelligence\tNNP\n",
      "''\t''\t''\n",
      "which\twhich\tWDT\n",
      "proposed\tpropose\tVBD\n",
      "what\twhat\tWP\n",
      "is\tbe\tVBZ\n",
      "now\tnow\tRB\n",
      "called\tcall\tVBN\n",
      "the\tthe\tDT\n",
      "Turing\tturing\tJJ\n",
      "test\ttest\tNN\n",
      "as\tas\tIN\n",
      "a\ta\tDT\n",
      "criterion\tcriterion\tNN\n",
      "of\tof\tIN\n",
      "intelligence\tintelligence\tNN\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "Georgetown\tGeorgetown\tNNP\n",
      "experiment\texperiment\tNN\n",
      "in\tin\tIN\n",
      "1954\t1954\tCD\n",
      "involved\tinvolve\tVBN\n",
      "fully\tfully\tRB\n",
      "automatic\tautomatic\tJJ\n",
      "translation\ttranslation\tNN\n",
      "of\tof\tIN\n",
      "more\tmore\tJJR\n",
      "than\tthan\tIN\n",
      "sixty\tsixty\tCD\n",
      "Russian\trussian\tJJ\n",
      "sentences\tsentence\tNNS\n",
      "into\tinto\tIN\n",
      "English\tEnglish\tNNP\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "authors\tauthor\tNNS\n",
      "claimed\tclaim\tVBD\n",
      "that\tthat\tIN\n",
      "within\twithin\tIN\n",
      "three\tthree\tCD\n",
      "or\tor\tCC\n",
      "five\tfive\tCD\n",
      "years\tyear\tNNS\n",
      ",\t,\t,\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "would\twould\tMD\n",
      "be\tbe\tVB\n",
      "a\ta\tDT\n",
      "solved\tsolve\tVBN\n",
      "problem\tproblem\tNN\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "real\treal\tJJ\n",
      "progress\tprogress\tNN\n",
      "was\tbe\tVBD\n",
      "much\tmuch\tRB\n",
      "slower\tslower\tJJR\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "after\tafter\tIN\n",
      "the\tthe\tDT\n",
      "ALPAC\tALPAC\tNNP\n",
      "report\treport\tNN\n",
      "in\tin\tIN\n",
      "1966\t1966\tCD\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "found\tfind\tVBD\n",
      "that\tthat\tIN\n",
      "ten\tten\tCD\n",
      "year\tyear\tNN\n",
      "long\tlong\tRB\n",
      "research\tresearch\tNN\n",
      "had\thave\tVBD\n",
      "failed\tfail\tVBN\n",
      "to\tto\tTO\n",
      "fulfill\tfulfill\tVB\n",
      "the\tthe\tDT\n",
      "expectations\texpectation\tNNS\n",
      ",\t,\t,\n",
      "funding\tfund\tVBG\n",
      "for\tfor\tIN\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "was\tbe\tVBD\n",
      "dramatically\tdramatically\tRB\n",
      "reduced\treduce\tVBN\n",
      ".\t.\t.\n",
      "Little\tlittle\tJJ\n",
      "further\tfurther\tJJ\n",
      "research\tresearch\tNN\n",
      "in\tin\tIN\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "was\tbe\tVBD\n",
      "conducted\tconduct\tVBN\n",
      "until\tuntil\tIN\n",
      "the\tthe\tDT\n",
      "late\tlate\tJJ\n",
      "1980s\t1980\tNNS\n",
      ",\t,\t,\n",
      "when\twhen\tWRB\n",
      "the\tthe\tDT\n",
      "first\tfirst\tJJ\n",
      "statistical\tstatistical\tJJ\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "systems\tsystem\tNNS\n",
      "were\tbe\tVBD\n",
      "developed\tdevelop\tVBN\n",
      ".\t.\t.\n",
      "Some\tsome\tDT\n",
      "notably\tnotably\tRB\n",
      "successful\tsuccessful\tJJ\n",
      "NLP\tnlp\tNN\n",
      "systems\tsystem\tNNS\n",
      "developed\tdevelop\tVBN\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "1960s\t1960\tNNS\n",
      "were\tbe\tVBD\n",
      "SHRDLU\tSHRDLU\tNNP\n",
      ",\t,\t,\n",
      "a\ta\tDT\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "system\tsystem\tNN\n",
      "working\twork\tVBG\n",
      "in\tin\tIN\n",
      "restricted\trestricted\tJJ\n",
      "``\t``\t``\n",
      "blocks\tblock\tNNS\n",
      "worlds\tworld\tNNS\n",
      "''\t''\t''\n",
      "with\twith\tIN\n",
      "restricted\trestricted\tJJ\n",
      "vocabularies\tvocabulary\tNNS\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "ELIZA\tELIZA\tNNP\n",
      ",\t,\t,\n",
      "a\ta\tDT\n",
      "simulation\tsimulation\tNN\n",
      "of\tof\tIN\n",
      "a\ta\tDT\n",
      "Rogerian\trogerian\tJJ\n",
      "psychotherapist\tpsychotherapist\tNN\n",
      ",\t,\t,\n",
      "written\twrite\tVBN\n",
      "by\tby\tIN\n",
      "Joseph\tJoseph\tNNP\n",
      "Weizenbaum\tWeizenbaum\tNNP\n",
      "between\tbetween\tIN\n",
      "1964\t1964\tCD\n",
      "to\tto\tTO\n",
      "1966\t1966\tCD\n",
      ".\t.\t.\n",
      "Using\tuse\tVBG\n",
      "almost\talmost\tRB\n",
      "no\tno\tDT\n",
      "information\tinformation\tNN\n",
      "about\tabout\tIN\n",
      "human\thuman\tJJ\n",
      "thought\tthought\tNN\n",
      "or\tor\tCC\n",
      "emotion\temotion\tNN\n",
      ",\t,\t,\n",
      "ELIZA\teliza\tNN\n",
      "sometimes\tsometimes\tRB\n",
      "provided\tprovide\tVBD\n",
      "a\ta\tDT\n",
      "startlingly\tstartlingly\tRB\n",
      "human-like\thuman-like\tJJ\n",
      "interaction\tinteraction\tNN\n",
      ".\t.\t.\n",
      "When\twhen\tWRB\n",
      "the\tthe\tDT\n",
      "``\t``\t``\n",
      "patient\tpatient\tNN\n",
      "''\t''\t''\n",
      "exceeded\texceed\tVBD\n",
      "the\tthe\tDT\n",
      "very\tvery\tRB\n",
      "small\tsmall\tJJ\n",
      "knowledge\tknowledge\tNN\n",
      "base\tbase\tNN\n",
      ",\t,\t,\n",
      "ELIZA\tELIZA\tNNP\n",
      "might\tmight\tMD\n",
      "provide\tprovide\tVB\n",
      "a\ta\tDT\n",
      "generic\tgeneric\tJJ\n",
      "response\tresponse\tNN\n",
      ",\t,\t,\n",
      "for\tfor\tIN\n",
      "example\texample\tNN\n",
      ",\t,\t,\n",
      "responding\trespond\tVBG\n",
      "to\tto\tTO\n",
      "``\t``\t``\n",
      "My\tmy\tPRP$\n",
      "head\thead\tNN\n",
      "hurts\thurt\tVBZ\n",
      "''\t''\t''\n",
      "with\twith\tIN\n",
      "``\t``\t``\n",
      "Why\twhy\tWRB\n",
      "do\tdo\tVBP\n",
      "you\tyou\tPRP\n",
      "say\tsay\tVB\n",
      "your\tyou\tPRP$\n",
      "head\thead\tNN\n",
      "hurts\thurt\tVBZ\n",
      "?\t?\t.\n",
      "''\t''\t''\n",
      ".\t.\t.\n",
      "During\tduring\tIN\n",
      "the\tthe\tDT\n",
      "1970s\t1970s\tCD\n",
      "many\tmany\tJJ\n",
      "programmers\tprogrammer\tNNS\n",
      "began\tbegin\tVBD\n",
      "to\tto\tTO\n",
      "write\twrite\tVB\n",
      "`\t`\t``\n",
      "conceptual\tconceptual\tJJ\n",
      "ontologies\tontology\tNNS\n",
      "'\t'\tPOS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "structured\tstructure\tVBD\n",
      "real-world\treal-world\tJJ\n",
      "information\tinformation\tNN\n",
      "into\tinto\tIN\n",
      "computer-understandable\tcomputer-understandable\tJJ\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Examples\texample\tNNS\n",
      "are\tbe\tVBP\n",
      "MARGIE\tMARGIE\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Schank\tSchank\tNNP\n",
      ",\t,\t,\n",
      "1975\t1975\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "SAM\tSAM\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Cullingford\tCullingford\tNNP\n",
      ",\t,\t,\n",
      "1978\t1978\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "PAM\tpam\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Wilensky\tWilensky\tNNP\n",
      ",\t,\t,\n",
      "1978\t1978\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "TaleSpin\tTaleSpin\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Meehan\tMeehan\tNNP\n",
      ",\t,\t,\n",
      "1976\t1976\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "QUALM\tqualm\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Lehnert\tlehnert\tNN\n",
      ",\t,\t,\n",
      "1977\t1977\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "Politics\tpolitics\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Carbonell\tCarbonell\tNNP\n",
      ",\t,\t,\n",
      "1979\t1979\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "Plot\tplot\tNN\n",
      "Units\tunit\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Lehnert\tLehnert\tNNP\n",
      "1981\t1981\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ".\t.\t.\n",
      "During\tduring\tIN\n",
      "this\tthis\tDT\n",
      "time\ttime\tNN\n",
      ",\t,\t,\n",
      "many\tmany\tJJ\n",
      "chatterbots\tchatterbot\tNNS\n",
      "were\tbe\tVBD\n",
      "written\twrite\tVBN\n",
      "including\tinclude\tVBG\n",
      "PARRY\tPARRY\tNNP\n",
      ",\t,\t,\n",
      "Racter\tRacter\tNNP\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "Jabberwacky\tJabberwacky\tNNP\n",
      ".\t.\t.\n",
      "Up\tup\tIN\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "1980s\t1980\tNNS\n",
      ",\t,\t,\n",
      "most\tmost\tJJS\n",
      "NLP\tnlp\tNNS\n",
      "systems\tsystem\tNNS\n",
      "were\tbe\tVBD\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "complex\tcomplex\tJJ\n",
      "sets\tset\tNNS\n",
      "of\tof\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      ".\t.\t.\n",
      "Starting\tstart\tVBG\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "late\tlate\tJJ\n",
      "1980s\t1980\tNNS\n",
      ",\t,\t,\n",
      "however\thowever\tRB\n",
      ",\t,\t,\n",
      "there\tthere\tEX\n",
      "was\tbe\tVBD\n",
      "a\ta\tDT\n",
      "revolution\trevolution\tNN\n",
      "in\tin\tIN\n",
      "NLP\tnlp\tNN\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "introduction\tintroduction\tNN\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "for\tfor\tIN\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      ".\t.\t.\n",
      "This\tthis\tDT\n",
      "was\tbe\tVBD\n",
      "due\tdue\tJJ\n",
      "to\tto\tTO\n",
      "both\tboth\tCC\n",
      "the\tthe\tDT\n",
      "steady\tsteady\tJJ\n",
      "increase\tincrease\tNN\n",
      "in\tin\tIN\n",
      "computational\tcomputational\tJJ\n",
      "power\tpower\tNN\n",
      "resulting\tresult\tVBG\n",
      "from\tfrom\tIN\n",
      "Moore\tMoore\tNNP\n",
      "'s\t's\tPOS\n",
      "Law\tlaw\tNN\n",
      "and\tand\tCC\n",
      "the\tthe\tDT\n",
      "gradual\tgradual\tJJ\n",
      "lessening\tlessen\tVBG\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "dominance\tdominance\tNN\n",
      "of\tof\tIN\n",
      "Chomskyan\tChomskyan\tNNP\n",
      "theories\ttheory\tNNS\n",
      "of\tof\tIN\n",
      "linguistics\tlinguistics\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "e.g.\te.g.\tFW\n",
      "transformational\ttransformational\tJJ\n",
      "grammar\tgrammar\tNN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "whose\twhose\tWP$\n",
      "theoretical\ttheoretical\tJJ\n",
      "underpinnings\tunderpinning\tNNS\n",
      "discouraged\tdiscourage\tVBD\n",
      "the\tthe\tDT\n",
      "sort\tsort\tNN\n",
      "of\tof\tIN\n",
      "corpus\tcorpus\tNN\n",
      "linguistics\tlinguistics\tNNS\n",
      "that\tthat\tWDT\n",
      "underlies\tunderlie\tVBZ\n",
      "the\tthe\tDT\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "approach\tapproach\tNN\n",
      "to\tto\tTO\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      ".\t.\t.\n",
      "Some\tsome\tDT\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "earliest-used\tearliest-used\tJJ\n",
      "machine\tmachine\tNN\n",
      "learning\tlearn\tVBG\n",
      "algorithms\talgorithm\tNNS\n",
      ",\t,\t,\n",
      "such\tsuch\tJJ\n",
      "as\tas\tIN\n",
      "decision\tdecision\tNN\n",
      "trees\ttree\tNNS\n",
      ",\t,\t,\n",
      "produced\tproduce\tVBD\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hard\thard\tJJ\n",
      "if-then\tif-then\tJJ\n",
      "rules\trule\tNNS\n",
      "similar\tsimilar\tJJ\n",
      "to\tto\tTO\n",
      "existing\texist\tVBG\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "Part\tpart\tNN\n",
      "of\tof\tIN\n",
      "speech\tspeech\tNN\n",
      "tagging\ttag\tVBG\n",
      "introduced\tintroduce\tVBN\n",
      "the\tthe\tDT\n",
      "use\tuse\tNN\n",
      "of\tof\tIN\n",
      "Hidden\tHidden\tNNP\n",
      "Markov\tMarkov\tNNP\n",
      "Models\tmodel\tNNS\n",
      "to\tto\tTO\n",
      "NLP\tNLP\tNNP\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "increasingly\tincreasingly\tRB\n",
      ",\t,\t,\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "focused\tfocus\tVBN\n",
      "on\ton\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "make\tmake\tVBP\n",
      "soft\tsoft\tJJ\n",
      ",\t,\t,\n",
      "probabilistic\tprobabilistic\tJJ\n",
      "decisions\tdecision\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "attaching\tattach\tVBG\n",
      "real-valued\treal-valued\tJJ\n",
      "weights\tweight\tNNS\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "features\tfeature\tNNS\n",
      "making\tmake\tVBG\n",
      "up\tup\tRP\n",
      "the\tthe\tDT\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "cache\tcache\tNN\n",
      "language\tlanguage\tNN\n",
      "models\tmodel\tNNS\n",
      "upon\tupon\tIN\n",
      "which\twhich\tWDT\n",
      "many\tmany\tJJ\n",
      "speech\tspeech\tNN\n",
      "recognition\trecognition\tNN\n",
      "systems\tsystem\tNNS\n",
      "now\tnow\tRB\n",
      "rely\trely\tVBP\n",
      "are\tbe\tVBP\n",
      "examples\texample\tNNS\n",
      "of\tof\tIN\n",
      "such\tsuch\tJJ\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      ".\t.\t.\n",
      "Such\tsuch\tJJ\n",
      "models\tmodel\tNNS\n",
      "are\tbe\tVBP\n",
      "generally\tgenerally\tRB\n",
      "more\tmore\tRBR\n",
      "robust\trobust\tJJ\n",
      "when\twhen\tWRB\n",
      "given\tgive\tVBN\n",
      "unfamiliar\tunfamiliar\tJJ\n",
      "input\tinput\tNN\n",
      ",\t,\t,\n",
      "especially\tespecially\tRB\n",
      "input\tinput\tNN\n",
      "that\tthat\tWDT\n",
      "contains\tcontain\tVBZ\n",
      "errors\terror\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "as\tas\tRB\n",
      "is\tbe\tVBZ\n",
      "very\tvery\tRB\n",
      "common\tcommon\tJJ\n",
      "for\tfor\tIN\n",
      "real-world\treal-world\tJJ\n",
      "data\tdatum\tNNS\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "produce\tproduce\tVB\n",
      "more\tmore\tJJR\n",
      "reliable\treliable\tJJ\n",
      "results\tresult\tNNS\n",
      "when\twhen\tWRB\n",
      "integrated\tintegrate\tVBN\n",
      "into\tinto\tIN\n",
      "a\ta\tDT\n",
      "larger\tlarger\tJJR\n",
      "system\tsystem\tNN\n",
      "comprising\tcomprise\tVBG\n",
      "multiple\tmultiple\tJJ\n",
      "subtasks\tsubtask\tNNS\n",
      ".\t.\t.\n",
      "Many\tmany\tJJ\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "notable\tnotable\tJJ\n",
      "early\tearly\tJJ\n",
      "successes\tsuccess\tNNS\n",
      "occurred\toccur\tVBD\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "field\tfield\tNN\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      ",\t,\t,\n",
      "due\tdue\tJJ\n",
      "especially\tespecially\tRB\n",
      "to\tto\tTO\n",
      "work\twork\tVB\n",
      "at\tat\tIN\n",
      "IBM\tIBM\tNNP\n",
      "Research\tResearch\tNNP\n",
      ",\t,\t,\n",
      "where\twhere\tWRB\n",
      "successively\tsuccessively\tRB\n",
      "more\tmore\tRBR\n",
      "complicated\tcomplicated\tJJ\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      "were\tbe\tVBD\n",
      "developed\tdevelop\tVBN\n",
      ".\t.\t.\n",
      "These\tthese\tDT\n",
      "systems\tsystem\tNNS\n",
      "were\tbe\tVBD\n",
      "able\table\tJJ\n",
      "to\tto\tTO\n",
      "take\ttake\tVB\n",
      "advantage\tadvantage\tNN\n",
      "of\tof\tIN\n",
      "existing\texist\tVBG\n",
      "multilingual\tmultilingual\tJJ\n",
      "textual\ttextual\tJJ\n",
      "corpora\tcorpora\tNN\n",
      "that\tthat\tWDT\n",
      "had\thave\tVBD\n",
      "been\tbe\tVBN\n",
      "produced\tproduce\tVBN\n",
      "by\tby\tIN\n",
      "the\tthe\tDT\n",
      "Parliament\tParliament\tNNP\n",
      "of\tof\tIN\n",
      "Canada\tCanada\tNNP\n",
      "and\tand\tCC\n",
      "the\tthe\tDT\n",
      "European\tEuropean\tNNP\n",
      "Union\tUnion\tNNP\n",
      "as\tas\tIN\n",
      "a\ta\tDT\n",
      "result\tresult\tNN\n",
      "of\tof\tIN\n",
      "laws\tlaw\tNNS\n",
      "calling\tcall\tVBG\n",
      "for\tfor\tIN\n",
      "the\tthe\tDT\n",
      "translation\ttranslation\tNN\n",
      "of\tof\tIN\n",
      "all\tall\tDT\n",
      "governmental\tgovernmental\tJJ\n",
      "proceedings\tproceedings\tNNS\n",
      "into\tinto\tIN\n",
      "all\tall\tDT\n",
      "official\tofficial\tJJ\n",
      "languages\tlanguage\tNNS\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "corresponding\tcorresponding\tJJ\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "government\tgovernment\tNN\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "most\tmost\tRBS\n",
      "other\tother\tJJ\n",
      "systems\tsystem\tNNS\n",
      "depended\tdepend\tVBD\n",
      "on\ton\tIN\n",
      "corpora\tcorpora\tNN\n",
      "specifically\tspecifically\tRB\n",
      "developed\tdevelop\tVBD\n",
      "for\tfor\tIN\n",
      "the\tthe\tDT\n",
      "tasks\ttask\tNNS\n",
      "implemented\timplement\tVBN\n",
      "by\tby\tIN\n",
      "these\tthese\tDT\n",
      "systems\tsystem\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "was\tbe\tVBD\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "and\tand\tCC\n",
      "often\toften\tRB\n",
      "continues\tcontinue\tVBZ\n",
      "to\tto\tTO\n",
      "be\tbe\tVB\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "a\ta\tDT\n",
      "major\tmajor\tJJ\n",
      "limitation\tlimitation\tNN\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "success\tsuccess\tNN\n",
      "of\tof\tIN\n",
      "these\tthese\tDT\n",
      "systems\tsystem\tNNS\n",
      ".\t.\t.\n",
      "As\tas\tIN\n",
      "a\ta\tDT\n",
      "result\tresult\tNN\n",
      ",\t,\t,\n",
      "a\ta\tDT\n",
      "great\tgreat\tJJ\n",
      "deal\tdeal\tNN\n",
      "of\tof\tIN\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "gone\tgo\tVBN\n",
      "into\tinto\tIN\n",
      "methods\tmethod\tNNS\n",
      "of\tof\tIN\n",
      "more\tmore\tJJR\n",
      "effectively\teffectively\tRB\n",
      "learning\tlearn\tVBG\n",
      "from\tfrom\tIN\n",
      "limited\tlimited\tJJ\n",
      "amounts\tamount\tNNS\n",
      "of\tof\tIN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Recent\trecent\tJJ\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "increasingly\tincreasingly\tRB\n",
      "focused\tfocus\tVBN\n",
      "on\ton\tIN\n",
      "unsupervised\tunsupervised\tJJ\n",
      "and\tand\tCC\n",
      "semi-supervised\tsemi-supervised\tJJ\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      ".\t.\t.\n",
      "Such\tsuch\tJJ\n",
      "algorithms\talgorithm\tNNS\n",
      "are\tbe\tVBP\n",
      "able\table\tJJ\n",
      "to\tto\tTO\n",
      "learn\tlearn\tVB\n",
      "from\tfrom\tIN\n",
      "data\tdatum\tNNS\n",
      "that\tthat\tWDT\n",
      "has\thave\tVBZ\n",
      "not\tnot\tRB\n",
      "been\tbe\tVBN\n",
      "hand-annotated\thand-annotate\tVBN\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "desired\tdesire\tVBN\n",
      "answers\tanswer\tNNS\n",
      ",\t,\t,\n",
      "or\tor\tCC\n",
      "using\tuse\tVBG\n",
      "a\ta\tDT\n",
      "combination\tcombination\tNN\n",
      "of\tof\tIN\n",
      "annotated\tannotated\tJJ\n",
      "and\tand\tCC\n",
      "non-annotated\tnon-annotated\tJJ\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Generally\tgenerally\tRB\n",
      ",\t,\t,\n",
      "this\tthis\tDT\n",
      "task\ttask\tNN\n",
      "is\tbe\tVBZ\n",
      "much\tmuch\tRB\n",
      "more\tmore\tRBR\n",
      "difficult\tdifficult\tJJ\n",
      "than\tthan\tIN\n",
      "supervised\tsupervised\tJJ\n",
      "learning\tlearning\tNN\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "typically\ttypically\tRB\n",
      "produces\tproduce\tVBZ\n",
      "less\tless\tJJR\n",
      "accurate\taccurate\tJJ\n",
      "results\tresult\tNNS\n",
      "for\tfor\tIN\n",
      "a\ta\tDT\n",
      "given\tgive\tVBN\n",
      "amount\tamount\tNN\n",
      "of\tof\tIN\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "there\tthere\tEX\n",
      "is\tbe\tVBZ\n",
      "an\ta\tDT\n",
      "enormous\tenormous\tJJ\n",
      "amount\tamount\tNN\n",
      "of\tof\tIN\n",
      "non-annotated\tnon-annotated\tJJ\n",
      "data\tdatum\tNNS\n",
      "available\tavailable\tJJ\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "including\tinclude\tVBG\n",
      ",\t,\t,\n",
      "among\tamong\tIN\n",
      "other\tother\tJJ\n",
      "things\tthing\tNNS\n",
      ",\t,\t,\n",
      "the\tthe\tDT\n",
      "entire\tentire\tJJ\n",
      "content\tcontent\tNN\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "World\tWorld\tNNP\n",
      "Wide\twide\tNN\n",
      "Web\tweb\tNN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "can\tcan\tMD\n",
      "often\toften\tRB\n",
      "make\tmake\tVB\n",
      "up\tup\tRP\n",
      "for\tfor\tIN\n",
      "the\tthe\tDT\n",
      "inferior\tinferior\tJJ\n",
      "results\tresult\tNNS\n",
      ".\t.\t.\n",
      "NLP\tnlp\tNN\n",
      "using\tuse\tVBG\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "Modern\tModern\tNNP\n",
      "NLP\tNLP\tNNP\n",
      "algorithms\talgorithm\tNNS\n",
      "are\tbe\tVBP\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      ",\t,\t,\n",
      "especially\tespecially\tRB\n",
      "statistical\tstatistical\tJJ\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "paradigm\tparadigm\tNN\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "is\tbe\tVBZ\n",
      "different\tdifferent\tJJ\n",
      "from\tfrom\tIN\n",
      "that\tthat\tDT\n",
      "of\tof\tIN\n",
      "most\tmost\tJJS\n",
      "prior\tprior\tJJ\n",
      "attempts\tattempt\tNNS\n",
      "at\tat\tIN\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      ".\t.\t.\n",
      "Prior\tprior\tRB\n",
      "implementations\timplementation\tNNS\n",
      "of\tof\tIN\n",
      "language-processing\tlanguage-processing\tJJ\n",
      "tasks\ttask\tNNS\n",
      "typically\ttypically\tRB\n",
      "involved\tinvolve\tVBD\n",
      "the\tthe\tDT\n",
      "direct\tdirect\tJJ\n",
      "hand\thand\tNN\n",
      "coding\tcoding\tNN\n",
      "of\tof\tIN\n",
      "large\tlarge\tJJ\n",
      "sets\tset\tNNS\n",
      "of\tof\tIN\n",
      "rules\trule\tNNS\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "paradigm\tparadigm\tNN\n",
      "calls\tcall\tVBZ\n",
      "instead\tinstead\tRB\n",
      "for\tfor\tIN\n",
      "using\tuse\tVBG\n",
      "general\tgeneral\tJJ\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "-\t-\t:\n",
      "often\toften\tRB\n",
      ",\t,\t,\n",
      "although\talthough\tIN\n",
      "not\tnot\tRB\n",
      "always\talways\tRB\n",
      ",\t,\t,\n",
      "grounded\tground\tVBN\n",
      "in\tin\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "inference\tinference\tNN\n",
      "-\t-\t:\n",
      "to\tto\tTO\n",
      "automatically\tautomatically\tRB\n",
      "learn\tlearn\tVB\n",
      "such\tsuch\tJJ\n",
      "rules\trule\tNNS\n",
      "through\tthrough\tIN\n",
      "the\tthe\tDT\n",
      "analysis\tanalysis\tNN\n",
      "of\tof\tIN\n",
      "large\tlarge\tJJ\n",
      "corpora\tcorpora\tNN\n",
      "of\tof\tIN\n",
      "typical\ttypical\tJJ\n",
      "real-world\treal-world\tJJ\n",
      "examples\texample\tNNS\n",
      ".\t.\t.\n",
      "A\ta\tDT\n",
      "corpus\tcorpus\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "plural\tplural\tNN\n",
      ",\t,\t,\n",
      "``\t``\t``\n",
      "corpora\tcorpora\tNN\n",
      "''\t''\t''\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "set\tset\tNN\n",
      "of\tof\tIN\n",
      "documents\tdocument\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "or\tor\tCC\n",
      "sometimes\tsometimes\tRB\n",
      ",\t,\t,\n",
      "individual\tindividual\tJJ\n",
      "sentences\tsentence\tNNS\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "that\tthat\tWDT\n",
      "have\thave\tVBP\n",
      "been\tbe\tVBN\n",
      "hand-annotated\thand-annotated\tJJ\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "correct\tcorrect\tJJ\n",
      "values\tvalue\tNNS\n",
      "to\tto\tTO\n",
      "be\tbe\tVB\n",
      "learned\tlearn\tVBN\n",
      ".\t.\t.\n",
      "Many\tmany\tJJ\n",
      "different\tdifferent\tJJ\n",
      "classes\tclass\tNNS\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "have\thave\tVBP\n",
      "been\tbe\tVBN\n",
      "applied\tapply\tVBN\n",
      "to\tto\tTO\n",
      "NLP\tnlp\tNN\n",
      "tasks\ttask\tNNS\n",
      ".\t.\t.\n",
      "These\tthese\tDT\n",
      "algorithms\talgorithm\tNNS\n",
      "take\ttake\tVBP\n",
      "as\tas\tRB\n",
      "input\tinput\tNN\n",
      "a\ta\tDT\n",
      "large\tlarge\tJJ\n",
      "set\tset\tNN\n",
      "of\tof\tIN\n",
      "``\t``\t``\n",
      "features\tfeature\tNNS\n",
      "''\t''\t''\n",
      "that\tthat\tWDT\n",
      "are\tbe\tVBP\n",
      "generated\tgenerate\tVBN\n",
      "from\tfrom\tIN\n",
      "the\tthe\tDT\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Some\tsome\tDT\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "earliest-used\tearliest-used\tJJ\n",
      "algorithms\talgorithm\tNNS\n",
      ",\t,\t,\n",
      "such\tsuch\tJJ\n",
      "as\tas\tIN\n",
      "decision\tdecision\tNN\n",
      "trees\ttree\tNNS\n",
      ",\t,\t,\n",
      "produced\tproduce\tVBD\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hard\thard\tJJ\n",
      "if-then\tif-then\tJJ\n",
      "rules\trule\tNNS\n",
      "similar\tsimilar\tJJ\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "that\tthat\tWDT\n",
      "were\tbe\tVBD\n",
      "then\tthen\tRB\n",
      "common\tcommon\tJJ\n",
      ".\t.\t.\n",
      "Increasingly\tincreasingly\tRB\n",
      ",\t,\t,\n",
      "however\thowever\tRB\n",
      ",\t,\t,\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "focused\tfocus\tVBN\n",
      "on\ton\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "make\tmake\tVBP\n",
      "soft\tsoft\tJJ\n",
      ",\t,\t,\n",
      "probabilistic\tprobabilistic\tJJ\n",
      "decisions\tdecision\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "attaching\tattach\tVBG\n",
      "real-valued\treal-valued\tJJ\n",
      "weights\tweight\tNNS\n",
      "to\tto\tTO\n",
      "each\teach\tDT\n",
      "input\tinput\tNN\n",
      "feature\tfeature\tNN\n",
      ".\t.\t.\n",
      "Such\tsuch\tJJ\n",
      "models\tmodel\tNNS\n",
      "have\thave\tVBP\n",
      "the\tthe\tDT\n",
      "advantage\tadvantage\tNN\n",
      "that\tthat\tIN\n",
      "they\tthey\tPRP\n",
      "can\tcan\tMD\n",
      "express\texpress\tVB\n",
      "the\tthe\tDT\n",
      "relative\trelative\tJJ\n",
      "certainty\tcertainty\tNN\n",
      "of\tof\tIN\n",
      "many\tmany\tJJ\n",
      "different\tdifferent\tJJ\n",
      "possible\tpossible\tJJ\n",
      "answers\tanswer\tNNS\n",
      "rather\trather\tRB\n",
      "than\tthan\tIN\n",
      "only\tonly\tRB\n",
      "one\tone\tCD\n",
      ",\t,\t,\n",
      "producing\tproduce\tVBG\n",
      "more\tmore\tJJR\n",
      "reliable\treliable\tJJ\n",
      "results\tresult\tNNS\n",
      "when\twhen\tWRB\n",
      "such\tsuch\tPDT\n",
      "a\ta\tDT\n",
      "model\tmodel\tNN\n",
      "is\tbe\tVBZ\n",
      "included\tinclude\tVBN\n",
      "as\tas\tIN\n",
      "a\ta\tDT\n",
      "component\tcomponent\tNN\n",
      "of\tof\tIN\n",
      "a\ta\tDT\n",
      "larger\tlarger\tJJR\n",
      "system\tsystem\tNN\n",
      ".\t.\t.\n",
      "Systems\tSystems\tNNPS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "algorithms\talgorithm\tNNS\n",
      "have\thave\tVBP\n",
      "many\tmany\tJJ\n",
      "advantages\tadvantage\tNNS\n",
      "over\tover\tIN\n",
      "hand-produced\thand-produced\tJJ\n",
      "rules\trule\tNNS\n",
      ":\t:\t:\n",
      "The\tthe\tDT\n",
      "learning\tlearn\tVBG\n",
      "procedures\tprocedure\tNNS\n",
      "used\tuse\tVBN\n",
      "during\tduring\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "automatically\tautomatically\tRB\n",
      "focus\tfocus\tVB\n",
      "on\ton\tIN\n",
      "the\tthe\tDT\n",
      "most\tmost\tRBS\n",
      "common\tcommon\tJJ\n",
      "cases\tcase\tNNS\n",
      ",\t,\t,\n",
      "whereas\twhereas\tIN\n",
      "when\twhen\tWRB\n",
      "writing\twrite\tVBG\n",
      "rules\trule\tNNS\n",
      "by\tby\tIN\n",
      "hand\thand\tNN\n",
      "it\tit\tPRP\n",
      "is\tbe\tVBZ\n",
      "often\toften\tRB\n",
      "not\tnot\tRB\n",
      "obvious\tobvious\tJJ\n",
      "at\tat\tIN\n",
      "all\tall\tDT\n",
      "where\twhere\tWRB\n",
      "the\tthe\tDT\n",
      "effort\teffort\tNN\n",
      "should\tshould\tMD\n",
      "be\tbe\tVB\n",
      "directed\tdirect\tVBN\n",
      ".\t.\t.\n",
      "Automatic\tAutomatic\tNNP\n",
      "learning\tlearn\tVBG\n",
      "procedures\tprocedure\tNNS\n",
      "can\tcan\tMD\n",
      "make\tmake\tVB\n",
      "use\tuse\tNN\n",
      "of\tof\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "inference\tinference\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "to\tto\tTO\n",
      "produce\tproduce\tVB\n",
      "models\tmodel\tNNS\n",
      "that\tthat\tWDT\n",
      "are\tbe\tVBP\n",
      "robust\trobust\tJJ\n",
      "to\tto\tTO\n",
      "unfamiliar\tunfamiliar\tJJ\n",
      "input\tinput\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "e.g.\te.g.\tFW\n",
      "containing\tcontain\tVBG\n",
      "words\tword\tNNS\n",
      "or\tor\tCC\n",
      "structures\tstructure\tNNS\n",
      "that\tthat\tWDT\n",
      "have\thave\tVBP\n",
      "not\tnot\tRB\n",
      "been\tbe\tVBN\n",
      "seen\tsee\tVBN\n",
      "before\tbefore\tIN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "and\tand\tCC\n",
      "to\tto\tTO\n",
      "erroneous\terroneous\tJJ\n",
      "input\tinput\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "e.g.\te.g.\tFW\n",
      "with\twith\tIN\n",
      "misspelled\tmisspell\tVBN\n",
      "words\tword\tNNS\n",
      "or\tor\tCC\n",
      "words\tword\tNNS\n",
      "accidentally\taccidentally\tRB\n",
      "omitted\tomit\tVBN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ".\t.\t.\n",
      "Generally\tgenerally\tRB\n",
      ",\t,\t,\n",
      "handling\thandle\tVBG\n",
      "such\tsuch\tJJ\n",
      "input\tinput\tNN\n",
      "gracefully\tgracefully\tRB\n",
      "with\twith\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "--\t--\t:\n",
      "or\tor\tCC\n",
      "more\tmore\tJJR\n",
      "generally\tgenerally\tRB\n",
      ",\t,\t,\n",
      "creating\tcreate\tVBG\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "that\tthat\tWDT\n",
      "make\tmake\tVBP\n",
      "soft\tsoft\tJJ\n",
      "decisions\tdecision\tNNS\n",
      "--\t--\t:\n",
      "extremely\textremely\tRB\n",
      "difficult\tdifficult\tJJ\n",
      ",\t,\t,\n",
      "error-prone\terror-prone\tJJ\n",
      "and\tand\tCC\n",
      "time-consuming\ttime-consuming\tJJ\n",
      ".\t.\t.\n",
      "Systems\tSystems\tNNPS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "automatically\tautomatically\tRB\n",
      "learning\tlearn\tVBG\n",
      "the\tthe\tDT\n",
      "rules\trule\tNNS\n",
      "can\tcan\tMD\n",
      "be\tbe\tVB\n",
      "made\tmake\tVBN\n",
      "more\tmore\tRBR\n",
      "accurate\taccurate\tJJ\n",
      "simply\tsimply\tRB\n",
      "by\tby\tIN\n",
      "supplying\tsupply\tVBG\n",
      "more\tmore\tJJR\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "systems\tsystem\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "can\tcan\tMD\n",
      "only\tonly\tRB\n",
      "be\tbe\tVB\n",
      "made\tmake\tVBN\n",
      "more\tmore\tRBR\n",
      "accurate\taccurate\tJJ\n",
      "by\tby\tIN\n",
      "increasing\tincrease\tVBG\n",
      "the\tthe\tDT\n",
      "complexity\tcomplexity\tNN\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "rules\trule\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "much\tmuch\tRB\n",
      "more\tmore\tRBR\n",
      "difficult\tdifficult\tJJ\n",
      "task\ttask\tNN\n",
      ".\t.\t.\n",
      "In\tin\tIN\n",
      "particular\tparticular\tJJ\n",
      ",\t,\t,\n",
      "there\tthere\tEX\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "limit\tlimit\tNN\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "complexity\tcomplexity\tNN\n",
      "of\tof\tIN\n",
      "systems\tsystem\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "hand-crafted\thand-crafted\tJJ\n",
      "rules\trule\tNNS\n",
      ",\t,\t,\n",
      "beyond\tbeyond\tIN\n",
      "which\twhich\tWDT\n",
      "the\tthe\tDT\n",
      "systems\tsystem\tNNS\n",
      "become\tbecome\tVBP\n",
      "more\tmore\tRBR\n",
      "and\tand\tCC\n",
      "more\tmore\tRBR\n",
      "unmanageable\tunmanageable\tJJ\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "creating\tcreate\tVBG\n",
      "more\tmore\tJJR\n",
      "data\tdatum\tNNS\n",
      "to\tto\tTO\n",
      "input\tinput\tNN\n",
      "to\tto\tTO\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "systems\tsystem\tNNS\n",
      "simply\tsimply\tRB\n",
      "requires\trequire\tVBZ\n",
      "a\ta\tDT\n",
      "corresponding\tcorresponding\tJJ\n",
      "increase\tincrease\tNN\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "number\tnumber\tNN\n",
      "of\tof\tIN\n",
      "man-hours\tman-hours\tNN\n",
      "worked\twork\tVBD\n",
      ",\t,\t,\n",
      "generally\tgenerally\tRB\n",
      "without\twithout\tIN\n",
      "significant\tsignificant\tJJ\n",
      "increases\tincrease\tNNS\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "complexity\tcomplexity\tNN\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "annotation\tannotation\tNN\n",
      "process\tprocess\tNN\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "subfield\tsubfield\tNN\n",
      "of\tof\tIN\n",
      "NLP\tNLP\tNNP\n",
      "devoted\tdevote\tVBN\n",
      "to\tto\tIN\n",
      "learning\tlearn\tVBG\n",
      "approaches\tapproach\tNNS\n",
      "is\tbe\tVBZ\n",
      "known\tknow\tVBN\n",
      "as\tas\tIN\n",
      "Natural\tnatural\tJJ\n",
      "Language\tlanguage\tNN\n",
      "Learning\tLearning\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "NLL\tNLL\tNNP\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "and\tand\tCC\n",
      "its\tits\tPRP$\n",
      "conference\tconference\tNN\n",
      "CoNLL\tconll\tNN\n",
      "and\tand\tCC\n",
      "peak\tpeak\tNN\n",
      "body\tbody\tNN\n",
      "SIGNLL\tSIGNLL\tNNP\n",
      "are\tbe\tVBP\n",
      "sponsored\tsponsor\tVBN\n",
      "by\tby\tIN\n",
      "ACL\tacl\tNN\n",
      ",\t,\t,\n",
      "recognizing\trecognize\tVBG\n",
      "also\talso\tRB\n",
      "their\tthey\tPRP$\n",
      "links\tlink\tNNS\n",
      "with\twith\tIN\n",
      "Computational\tcomputational\tJJ\n",
      "Linguistics\tlinguistics\tNNS\n",
      "and\tand\tCC\n",
      "Language\tLanguage\tNNP\n",
      "Acquisition\tAcquisition\tNNP\n",
      ".\t.\t.\n",
      "When\twhen\tWRB\n",
      "the\tthe\tDT\n",
      "aims\taim\tNNS\n",
      "of\tof\tIN\n",
      "computational\tcomputational\tJJ\n",
      "language\tlanguage\tNN\n",
      "learning\tlearn\tVBG\n",
      "research\tresearch\tNN\n",
      "is\tbe\tVBZ\n",
      "to\tto\tTO\n",
      "understand\tunderstand\tVB\n",
      "more\tmore\tJJR\n",
      "about\tabout\tIN\n",
      "human\thuman\tJJ\n",
      "language\tlanguage\tNN\n",
      "acquisition\tacquisition\tNN\n",
      ",\t,\t,\n",
      "or\tor\tCC\n",
      "psycholinguistics\tpsycholinguistic\tNNS\n",
      ",\t,\t,\n",
      "NLL\tnll\tNN\n",
      "overlaps\toverlap\tVBZ\n",
      "into\tinto\tIN\n",
      "the\tthe\tDT\n",
      "related\trelated\tJJ\n",
      "field\tfield\tNN\n",
      "of\tof\tIN\n",
      "Computational\tComputational\tNNP\n",
      "Psycholinguistics\tPsycholinguistics\tNNPS\n",
      ".\t.\t.\n"
     ]
    }
   ],
   "source": [
    "for word_tag, lemma_tag, pos_tag in zip(root.iter(\"word\"), root.iter(\"lemma\"), root.iter(\"POS\")):\n",
    "    args = (word_tag.text, lemma_tag.text, pos_tag.text)\n",
    "    print(\"%s\\t%s\\t%s\" % args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55. 固有表現抽出\n",
    "入力文中の人名をすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan\n",
      "Turing\n",
      "Joseph\n",
      "Weizenbaum\n",
      "MARGIE\n",
      "Schank\n",
      "Wilensky\n",
      "Meehan\n",
      "Lehnert\n",
      "Carbonell\n",
      "Lehnert\n",
      "Racter\n",
      "Jabberwacky\n",
      "Moore\n"
     ]
    }
   ],
   "source": [
    "for word_tag, ner_tag in zip(root.iter(\"word\"), root.iter(\"NER\")):\n",
    "    if ner_tag.text == \"PERSON\":\n",
    "        print(word_tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56. 共参照解析\n",
    "Stanford Core NLPの共参照解析の結果に基づき，文中の参照表現（mention）を代表参照表現（representative mention）に置換せよ．ただし，置換するときは，「代表参照表現（参照表現）」のように，元の参照表現が分かるように配慮せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreferences = []\n",
    "for coreference_tag in list(root.iter(\"coreference\"))[0]:\n",
    "    mentions = []\n",
    "    for mention_tag in coreference_tag.iter(\"mention\"):\n",
    "        mention = {}\n",
    "        # sentence, start, end, head, text\n",
    "        children = list(mention_tag)\n",
    "        mention[\"sentence\"] = int(children[0].text)\n",
    "        mention[\"start\"] = int(children[1].text)\n",
    "        mention[\"end\"] = int(children[2].text)\n",
    "        mention[\"text\"] = children[4].text\n",
    "        mentions.append(mention)\n",
    "    coreferences.append(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_56 = deepcopy(sentences_nlp)\n",
    "\n",
    "for mentions in coreferences:\n",
    "    representative_mention = mentions[0][\"text\"]\n",
    "    for mention in mentions[1:]:\n",
    "        foo = (mention[\"sentence\"], mention[\"start\"], mention[\"end\"], mention[\"text\"])\n",
    "        sentences_56[foo[0]-1][foo[1]-1] = representative_mention + \"(\" + foo[3] + \")\"\n",
    "        for i in range(foo[1], foo[2]-1):\n",
    "            sentences_56[foo[0]-1][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing From Wikipedia , the free encyclopedia Natural language processing -LRB- NLP -RRB- is a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages.\n",
      "As such , NLP(NLP) is related to the area of humani-computer interaction.\n",
      "Many challenges in NLP(NLP) involve natural language understanding , that is , enabling computers to derive meaning from human or natural language input , and others involve natural language generation.\n",
      "History The history of NLP(NLP) generally starts in the 1950s , although work can be found from earlier periods.\n",
      "In 1950 , Alan Turing published an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence.\n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English.\n",
      "The authors claimed that within three or five years , machine translation would be a solved problem.\n",
      "However , real progress was much slower , and after the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations , funding for machine translation was dramatically reduced.\n",
      "Little further research in machine translation(machine translation) was conducted until the late 1980s , when the first statistical machine translation systems were developed.\n",
      "Some notably successful NLP systems developed in the 1960s were SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies , and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 to 1966(1966).\n",
      "Using almost no information about human thought or emotion , ELIZA(ELIZA) sometimes provided a startlingly human-like interaction.\n",
      "When the `` patient '' exceeded the very small knowledge base , ELIZA(ELIZA) might provide a generic response , for example , responding to `` My head hurts '' with `` Why do you say you(your) head hurts ?''\n",
      ".During the 1970s many programmers began to write ` conceptual ontologies ' , which structured real-world information into computer-understandable data.\n",
      "Examples are MARGIE -LRB- Schank , 1975 -RRB- , SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978(1978) -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-.\n",
      "During this time , many chatterbots were written including PARRY , Racter , and Jabberwacky.\n",
      "Up to the 1980s , most NLP(NLP) systems were based on complex sets of hand-written rules.\n",
      "Starting in the late 1980s , however , there was a revolution in NLP(NLP) with the introduction of machine learning algorithms for language processing.\n",
      "This was due to both the steady increase in computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.\n",
      "Some of the earliest-used machine learning algorithms , such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules.\n",
      "However , Part of speech tagging introduced the use of Hidden Markov Models to NLP , and increasingly , research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data.\n",
      "The cache language models upon which many speech recognition systems now rely are examples of such statistical models.\n",
      "Such models are generally more robust when given unfamiliar input , especially input that contains errors -LRB- as is very common for real-world data -RRB- , and produce more reliable results when integrated into a larger system comprising multiple subtasks.\n",
      "Many of the notable early successes occurred in the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed.\n",
      "many speech recognition systems(These systems) were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.\n",
      "However , most other systems depended on corpora specifically developed for the tasks implemented by these systems , which was -LRB- and often continues to be -RRB- a major limitation in the success of many speech recognition systems(these systems).\n",
      "As a result , a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n",
      "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.\n",
      "Such algorithms are able to learn from data that has not been hand-annotated with the desired answers , or using a combination of annotated and non-annotated data.\n",
      "Generally , this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data.\n",
      "However , there is an enormous amount of non-annotated data available -LRB- including , among other things , the entire content of the World Wide Web -RRB- , which can often make up for the inferior results.\n",
      "NLP using machine learning Modern NLP algorithms are based on machine learning , especially statistical machine learning.\n",
      "The machine-learning paradigm(The paradigm of machine learning) is different from that of most prior attempts at language processing.\n",
      "Prior implementations of language-processing tasks typically involved the direct hand coding of large sets of rules.\n",
      "The machine-learning paradigm calls instead for using general learning algorithms - often , although not always , grounded in statistical inference - to automatically learn such rules through the analysis of large corpora of typical real-world examples.\n",
      "A corpus -LRB- plural , `` corpora '' -RRB- is a set of documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned.\n",
      "Many different classes of machine learning algorithms have been applied to NLP(NLP) tasks.\n",
      "machine learning algorithms(These algorithms) take as input a large set of `` features '' that are generated from the input data(the input data).\n",
      "Some of machine learning algorithms(the earliest-used algorithms) , such as decision trees , produced systems of hard if-then rules similar to the systems of hand-written rules that were then common.\n",
      "Increasingly , however , research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature.\n",
      "Such models have the advantage that Such models(they) can express the relative certainty of many different possible answers rather than only one , producing more reliable results when such a model is included as a component of a larger system.\n",
      "Systems based on machine-learning algorithms have many advantages over hand-produced rules : The learning procedures used during machine learning automatically focus on the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed.\n",
      "Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input -LRB- e.g. containing words or structures that have not been seen before -RRB- and to erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-.\n",
      "Generally , handling such input gracefully with hand-written rules -- or more generally , creating systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming.\n",
      "Systems based on automatically learning the rules can be made more accurate simply by supplying more input data.\n",
      "However , systems based on hand-written rules can only be made more accurate by increasing the complexity of the rules , which is a much more difficult task.\n",
      "In particular , there is a limit to the complexity of systems based on hand-crafted rules , beyond which many speech recognition systems(the systems) become more and more unmanageable.\n",
      "However , creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked , generally without significant increases in the complexity of the annotation process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subfield of NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and NLL(its) conference CoNLL and peak body SIGNLL are sponsored by ACL , recognizing also their links with Computational Linguistics and Language Acquisition.\n",
      "When the aims of computational language learning research is to understand more about human language acquisition , or psycholinguistics , NLL(NLL) overlaps into the related field of Computational Psycholinguistics.\n"
     ]
    }
   ],
   "source": [
    "for sentence_56 in sentences_56:\n",
    "    for idx, word in enumerate(sentence_56):\n",
    "        if word is not None:\n",
    "            if idx == 0:\n",
    "                print(word, end=\"\")\n",
    "            elif idx < len(sentence_56)-1:\n",
    "                print(\" \" + word, end=\"\")\n",
    "            else:\n",
    "                print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57. 係り受け解析\n",
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）を有向グラフとして可視化せよ．可視化には，係り受け木を[DOT言語](http://ja.wikipedia.org/wiki/DOT%E8%A8%80%E8%AA%9E)に変換し，[Graphviz](http://www.graphviz.org/)を用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，[pydot](https://code.google.com/p/pydot/)を使うとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_57 = []\n",
    "for sentence_tag in list(root.iter(\"sentences\"))[0].iter(\"sentence\"):\n",
    "    sentence_57 = {}\n",
    "\n",
    "    nodes = {0: \"ROOT\"}\n",
    "    for token_tag in sentence_tag.iter(\"token\"):\n",
    "        i = token_tag.get(\"id\")\n",
    "        nodes[i] = list(token_tag)[0].text\n",
    "    sentence_57[\"nodes\"] = nodes\n",
    "\n",
    "    dependencies_tag = list(sentence_tag.iter(\"dependencies\"))[1]\n",
    "    edges = {}\n",
    "    for dep_tag in list(dependencies_tag):\n",
    "        edge = list(dep_tag)\n",
    "        edge_from, edge_to = edge[0].get(\"idx\"), edge[1].get(\"idx\")\n",
    "        if edge_from in edges:\n",
    "            edges[edge_from].append(edge_to)\n",
    "        else:\n",
    "            edges[edge_from] = [edge_to]\n",
    "    sentence_57[\"edges\"] = edges\n",
    "\n",
    "    sentences_57.append(sentence_57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dependency_tree(sentence_57: dict):\n",
    "    digraph = graphviz.Digraph()\n",
    "\n",
    "    for i, label in sentence_57[\"nodes\"].items():\n",
    "        digraph.node(str(i), label=label)\n",
    "\n",
    "    for edge_from, edges_to in sentence_57[\"edges\"].items():\n",
    "        for edge_to in edges_to:\n",
    "            digraph.edge(edge_from, edge_to)\n",
    "\n",
    "    digraph.view()\n",
    "    return digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"2000pt\" height=\"548pt\"\n",
       " viewBox=\"0.00 0.00 1999.84 548.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 544)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-544 1995.8426,-544 1995.8426,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1151.7958\" cy=\"-522\" rx=\"39.7935\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1151.7958\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ROOT</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1151.7958\" cy=\"-450\" rx=\"31.3957\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1151.7958\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">field</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;18 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1151.7958,-503.8314C1151.7958,-496.131 1151.7958,-486.9743 1151.7958,-478.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1155.2959,-478.4132 1151.7958,-468.4133 1148.2959,-478.4133 1155.2959,-478.4132\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"46.7958\" cy=\"-306\" rx=\"46.5926\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"46.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Natural</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"164.7958\" cy=\"-306\" rx=\"53.0913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">language</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"271.7958\" cy=\"-378\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">processing</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M230.1184,-364.705C195.909,-353.787 146.2075,-337.9124 102.7958,-324 99.4863,-322.9394 96.0671,-321.8427 92.6258,-320.7382\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.5332,-317.3536 82.9419,-317.6285 91.393,-324.0184 93.5332,-317.3536\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247.2479,-361.4817C232.4632,-351.5332 213.4572,-338.7441 197.4195,-327.9524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.1114,-324.8722 188.8608,-322.1933 195.2034,-330.6798 199.1114,-324.8722\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"271.7958\" cy=\"-306\" rx=\"35.9954\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">From</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271.7958,-359.8314C271.7958,-352.131 271.7958,-342.9743 271.7958,-334.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"275.2959,-334.4132 271.7958,-324.4133 268.2959,-334.4133 275.2959,-334.4132\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"383.7958\" cy=\"-306\" rx=\"57.6901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Wikipedia</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M297.4909,-361.4817C312.9998,-351.5118 332.9463,-338.689 349.756,-327.8828\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"351.7012,-330.7931 358.2203,-322.4414 347.9159,-324.9049 351.7012,-330.7931\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"715.7958\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"715.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">,</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"486.7958\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"486.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">the</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"560.7958\" cy=\"-306\" rx=\"29.4969\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"560.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">free</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"679.7958\" cy=\"-306\" rx=\"71.4873\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"679.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encyclopedia</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"815.7958\" cy=\"-306\" rx=\"46.5926\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"815.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Natural</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"933.7958\" cy=\"-306\" rx=\"53.0913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"933.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">language</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"822.7958\" cy=\"-378\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"822.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">processing</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;7 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>12&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M777.1071,-365.7564C768.7195,-363.6972 760.0178,-361.6847 751.7958,-360 650.8652,-339.3186 620.9193,-355.4087 522.7958,-324 520.8991,-323.3929 518.9786,-322.6978 517.063,-321.942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"518.2206,-318.627 507.6596,-317.7814 515.3883,-325.0284 518.2206,-318.627\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;8 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>12&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M776.2282,-366.0827C768.0899,-364.0318 759.7002,-361.9379 751.7958,-360 684.3682,-343.4691 665.4183,-346.6595 599.7958,-324 597.5358,-323.2196 595.2302,-322.3524 592.9257,-321.4322\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"594.1506,-318.1495 583.5796,-317.4391 591.4003,-324.5866 594.1506,-318.1495\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;9 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>12&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M791.767,-362.3771C771.0466,-351.9444 743.5649,-338.1075 721.0134,-326.7529\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"722.5092,-323.5874 712.0034,-322.2164 719.3612,-329.8397 722.5092,-323.5874\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;10 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>12&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M821.0295,-359.8314C820.2808,-352.131 819.3906,-342.9743 818.5586,-334.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"822.0374,-334.0276 817.586,-324.4133 815.0702,-334.7051 822.0374,-334.0276\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;11 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>12&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M848.2615,-361.4817C863.7409,-351.441 883.6809,-338.507 900.4139,-327.6531\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"902.3463,-330.5716 908.8312,-322.1933 898.5369,-324.6988 902.3463,-330.5716\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1036.7958\" cy=\"-306\" rx=\"31.6951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1036.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">NLP</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M867.7022,-365.4717C902.8976,-355.2965 952.9204,-340.0466 995.7958,-324 998.0073,-323.1723 1000.2712,-322.2877 1002.544,-321.3712\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1003.9504,-324.5768 1011.8252,-317.4889 1001.2491,-318.119 1003.9504,-324.5768\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"990.7958\" cy=\"-234\" rx=\"36.2938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"990.7958\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;LRB&#45;</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;13 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>14&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1025.8945,-288.937C1020.3617,-280.277 1013.5231,-269.5731 1007.3563,-259.9207\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1010.2719,-257.9833 1001.9385,-251.4407 1004.373,-261.752 1010.2719,-257.9833\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1081.7958\" cy=\"-234\" rx=\"37.0935\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1081.7958\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;RRB&#45;</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1047.4602,-288.937C1052.8727,-280.277 1059.5626,-269.5731 1065.5954,-259.9207\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1068.5634,-261.7757 1070.8954,-251.4407 1062.6274,-258.0657 1068.5634,-261.7757\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"943.7958\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"943.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">is</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1015.7958\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1015.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">a</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>18&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1120.7347,-447.4586C994.9197,-437.1647 521.3433,-398.4175 341.5856,-383.7101\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"341.7059,-380.2083 331.4537,-382.8811 341.135,-387.185 341.7059,-380.2083\"/>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>18&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1120.4404,-449.2506C1052.0025,-446.8675 884.7253,-436.9624 751.7958,-396 749.8927,-395.4135 747.967,-394.7346 746.0476,-393.9909\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"747.1977,-390.6736 736.6339,-389.8631 744.3866,-397.0844 747.1977,-390.6736\"/>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;12 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>18&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1122.5993,-443.6105C1068.8633,-431.8506 953.3225,-406.5651 882.4041,-391.045\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"882.7943,-387.5476 872.2772,-388.8287 881.2977,-394.3858 882.7943,-387.5476\"/>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;16 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>18&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1123.3073,-442.5595C1088.7902,-433.203 1029.1293,-415.9295 979.7958,-396 977.9979,-395.2737 976.1668,-394.4933 974.3307,-393.6792\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"975.7812,-390.4937 965.2409,-389.4206 972.8115,-396.8325 975.7812,-390.4937\"/>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1128.7253,-437.7862C1106.012,-425.7615 1071.1936,-407.3282 1046.2251,-394.1096\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1047.6593,-390.9087 1037.1838,-389.323 1044.384,-397.0952 1047.6593,-390.9087\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1106.7958\" cy=\"-378\" rx=\"46.2923\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1106.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">science</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;21 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>18&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1141.1315,-432.937C1135.8136,-424.4284 1129.2626,-413.9468 1123.3133,-404.4279\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1126.1216,-402.3174 1117.8536,-395.6924 1120.1856,-406.0274 1126.1216,-402.3174\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1197.7958\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1197.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">,</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;22 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>18&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1162.6972,-432.937C1168.3114,-424.1496 1175.27,-413.2579 1181.507,-403.4956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1184.5382,-405.2519 1186.9727,-394.9405 1178.6394,-401.4831 1184.5382,-405.2519\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1308.7958\" cy=\"-378\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1308.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intelligence</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;24 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>18&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1176.3271,-438.75C1200.1146,-427.8411 1236.7167,-411.0554 1265.4232,-397.8906\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1267.1951,-400.9286 1274.8259,-393.5786 1264.2771,-394.5658 1267.1951,-400.9286\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>25</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1419.7958\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1419.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">,</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;25 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>18&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1182.1085,-445.2885C1227.0435,-437.784 1313.579,-421.3266 1383.7958,-396 1385.6692,-395.3243 1387.5716,-394.5759 1389.4734,-393.7795\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1391.1922,-396.8426 1398.8398,-389.5102 1388.2888,-390.4731 1391.1922,-396.8426\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1492.7958\" cy=\"-378\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1492.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;26 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>18&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1182.6815,-447.3612C1238.397,-441.98 1358.9372,-427.4851 1455.7958,-396 1457.732,-395.3706 1459.6956,-394.6583 1461.6566,-393.8893\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1463.5269,-396.8925 1471.3002,-389.6935 1460.7342,-390.4738 1463.5269,-396.8925\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1597.7958\" cy=\"-378\" rx=\"59.2899\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1597.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linguistics</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;27 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>18&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1182.8745,-446.8056C1247.7466,-439.8651 1402.1387,-421.9218 1529.7958,-396 1534.5568,-395.0332 1539.4802,-393.9323 1544.4005,-392.7622\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1545.5726,-396.078 1554.4428,-390.2841 1543.8955,-389.2819 1545.5726,-396.078\"/>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>40</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1701.7958\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1701.7958\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">.</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;40 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>18&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1183.0061,-448.1882C1279.8434,-442.3368 1574.1762,-422.7589 1665.7958,-396 1667.9213,-395.3792 1670.0721,-394.6364 1672.2095,-393.8111\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1673.6234,-397.0129 1681.3736,-389.789 1670.81,-390.6031 1673.6234,-397.0129\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1113.7958\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1113.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">of</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1214.7958\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1214.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">computer</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;19 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>21&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1108.5622,-359.8314C1109.3109,-352.131 1110.2011,-342.9743 1111.0331,-334.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1114.5215,-334.7051 1112.0057,-324.4133 1107.5543,-334.0276 1114.5215,-334.7051\"/>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1130.2302,-362.3771C1145.3395,-352.3042 1165.2091,-339.0578 1181.8915,-327.9363\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1183.9036,-330.8014 1190.2826,-322.3421 1180.0207,-324.977 1183.9036,-330.8014\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>23</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1338.7958\" cy=\"-306\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1338.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">artificial</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;23 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>24&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1316.3661,-359.8314C1319.7314,-351.7547 1323.7641,-342.0761 1327.4763,-333.1668\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1330.7165,-334.4904 1331.3319,-323.9134 1324.2549,-331.798 1330.7165,-334.4904\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>28</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1597.7958\" cy=\"-306\" rx=\"59.5901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1597.7958\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">concerned</text>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;28 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>27&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1597.7958,-359.8314C1597.7958,-352.131 1597.7958,-342.9743 1597.7958,-334.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1601.2959,-334.4132 1597.7958,-324.4133 1594.2959,-334.4133 1601.2959,-334.4132\"/>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>31</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1597.7958\" cy=\"-234\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1597.7958\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">interactions</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;31 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>28&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1597.7958,-287.8314C1597.7958,-280.131 1597.7958,-270.9743 1597.7958,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1601.2959,-262.4132 1597.7958,-252.4133 1594.2959,-262.4133 1601.2959,-262.4132\"/>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1521.7958\" cy=\"-162\" rx=\"31.3957\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1521.7958\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">with</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1597.7958\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1597.7958\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">the</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1579.3984,-216.5708C1569.2882,-206.9927 1556.6287,-194.9995 1545.7543,-184.6975\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1547.8803,-181.8903 1538.2136,-177.5537 1543.066,-186.972 1547.8803,-181.8903\"/>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1597.7958,-215.8314C1597.7958,-208.131 1597.7958,-198.9743 1597.7958,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1601.2959,-190.4132 1597.7958,-180.4133 1594.2959,-190.4133 1601.2959,-190.4132\"/>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>33</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1702.7958\" cy=\"-162\" rx=\"60.3893\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1702.7958\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">computers</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;33 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>31&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1622.4137,-217.1192C1636.734,-207.2996 1654.9532,-194.8064 1670.4243,-184.1976\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1672.4264,-187.0686 1678.6944,-178.5267 1668.4677,-181.2955 1672.4264,-187.0686\"/>\n",
       "</g>\n",
       "<!-- 32 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>32</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1606.7958\" cy=\"-90\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1606.7958\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">between</text>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;32 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>33&#45;&gt;32</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1680.0452,-144.937C1667.1886,-135.2945 1650.9535,-123.1182 1637.0369,-112.6808\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1638.8224,-109.6449 1628.7224,-106.4449 1634.6224,-115.245 1638.8224,-109.6449\"/>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>34</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1702.7958\" cy=\"-90\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1702.7958\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;34 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>33&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1702.7958,-143.8314C1702.7958,-136.131 1702.7958,-126.9743 1702.7958,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1706.2959,-118.4132 1702.7958,-108.4133 1699.2959,-118.4133 1706.2959,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 39 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>39</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1806.7958\" cy=\"-90\" rx=\"57.6901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1806.7958\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">languages</text>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;39 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>33&#45;&gt;39</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1726.9169,-145.3008C1741.0932,-135.4865 1759.1942,-122.955 1774.5796,-112.3035\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1776.5759,-115.1785 1782.8056,-106.6087 1772.5914,-109.4231 1776.5759,-115.1785\"/>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>35</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1659.7958\" cy=\"-18\" rx=\"42.4939\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1659.7958\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">human</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>36</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1756.7958\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1756.7958\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;LRB&#45;</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>37</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1855.7958\" cy=\"-18\" rx=\"44.393\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1855.7958\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">natural</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>38</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1954.7958\" cy=\"-18\" rx=\"37.0935\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1954.7958\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;RRB&#45;</text>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;35 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>39&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1775.6209,-74.7307C1752.7051,-63.5066 1721.4626,-48.2041 1697.2004,-36.3206\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1698.4635,-33.042 1687.9433,-31.7865 1695.3844,-39.3284 1698.4635,-33.042\"/>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;36 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>39&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1794.4363,-72.2022C1788.414,-63.5301 1781.0636,-52.9455 1774.4618,-43.4389\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1777.2477,-41.3145 1768.6689,-35.0972 1771.4981,-45.3073 1777.2477,-41.3145\"/>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;37 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>39&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1818.9082,-72.2022C1824.664,-63.7448 1831.6576,-53.4685 1838.0014,-44.147\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1841.09,-45.8294 1843.8228,-35.593 1835.303,-41.891 1841.09,-45.8294\"/>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;38 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>39&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1838.1828,-74.7307C1861.9585,-63.1641 1894.637,-47.2664 1919.3529,-35.2425\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1920.9392,-38.3631 1928.4004,-30.841 1917.8769,-32.0684 1920.9392,-38.3631\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f9aafa08a20>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_dependency_tree(sentences_57[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"616pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 616.44 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-328 612.4389,-328 612.4389,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"224.4971\" cy=\"-306\" rx=\"39.7935\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.4971\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ROOT</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"224.4971\" cy=\"-234\" rx=\"44.393\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.4971\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">related</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M224.4971,-287.8314C224.4971,-280.131 224.4971,-270.9743 224.4971,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"227.9972,-262.4132 224.4971,-252.4133 220.9972,-262.4133 227.9972,-262.4132\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"32.4971\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.4971\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">As</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"32.4971\" cy=\"-162\" rx=\"32.4942\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.4971\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">such</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M32.4971,-143.8314C32.4971,-136.131 32.4971,-126.9743 32.4971,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"35.9972,-118.4132 32.4971,-108.4133 28.9972,-118.4133 35.9972,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109.4971\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.4971\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">,</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"186.4971\" cy=\"-162\" rx=\"31.6951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"186.4971\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">NLP</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"263.4971\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"263.4971\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">is</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>6&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M190.3584,-222.5579C159.5856,-212.0629 113.2074,-195.7948 73.4971,-180 71.443,-179.183 69.3392,-178.3253 67.2223,-177.4462\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"68.5417,-174.204 57.9694,-173.5135 65.8035,-180.6463 68.5417,-174.204\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>6&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M200.3893,-218.9064C182.1948,-207.5151 157.1739,-191.8498 137.9897,-179.8388\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.6977,-176.7788 129.3645,-174.4387 135.9831,-182.7119 139.6977,-176.7788\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.1039,-216.2022C210.6533,-207.7695 205.2483,-197.5285 200.3401,-188.2288\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.4142,-186.5548 195.6512,-179.3446 197.2235,-189.8221 203.4142,-186.5548\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.1376,-216.2022C238.7391,-207.7071 244.3347,-197.3767 249.4017,-188.0223\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252.5508,-189.5572 254.2361,-179.0972 246.3957,-186.2231 252.5508,-189.5572\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339.4971\" cy=\"-162\" rx=\"31.3957\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.4971\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">area</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;9 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M248.6049,-218.9064C266.3446,-207.7998 290.5735,-192.6304 309.555,-180.7464\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.5133,-183.6497 318.1318,-175.3765 307.7986,-177.7167 311.5133,-183.6497\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"415.4971\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"415.4971\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">.</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M259.7635,-223.143C291.4999,-213.037 339.1991,-197.0112 379.4971,-180 381.2836,-179.2459 383.1057,-178.4437 384.9348,-177.6129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"386.4719,-180.7576 394.0057,-173.3082 383.4707,-174.4336 386.4719,-180.7576\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"267.4971\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"267.4971\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">to</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339.4971\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.4971\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">the</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M323.8742,-146.3771C313.9274,-136.4302 300.8859,-123.3888 289.8518,-112.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1421,-109.6953 282.5962,-105.099 287.1924,-114.645 292.1421,-109.6953\"/>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M339.4971,-143.8314C339.4971,-136.131 339.4971,-126.9743 339.4971,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.9972,-118.4132 339.4971,-108.4133 335.9972,-118.4133 342.9972,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"446.4971\" cy=\"-90\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"446.4971\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">interaction</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M359.8749,-148.2879C374.8488,-138.2119 395.53,-124.2956 412.9293,-112.5877\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"415.3387,-115.1851 421.6813,-106.6985 411.4307,-109.3775 415.3387,-115.1851\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"377.4971\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.4971\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">of</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"515.4971\" cy=\"-18\" rx=\"92.8835\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"515.4971\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">humani&#45;computer</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>12&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M429.7941,-72.5708C420.6407,-63.0194 409.1856,-51.0662 399.3314,-40.7836\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401.6185,-38.1116 392.1725,-33.3134 396.5646,-42.955 401.6185,-38.1116\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;11 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M463.2001,-72.5708C471.6344,-63.7698 482.0228,-52.9297 491.3124,-43.2362\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"494.0765,-45.4105 498.4686,-35.7689 489.0226,-40.5671 494.0765,-45.4105\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f9aafa13ef0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_dependency_tree(sentences_57[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58. タプルの抽出\n",
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）に基づき，「主語 述語 目的語」の組をタブ区切り形式で出力せよ．ただし，主語，述語，目的語の定義は以下を参考にせよ．\n",
    "* 述語: nsubj関係とdobj関係の子（dependant）を持つ単語\n",
    "* 主語: 述語からnsubj関係にある子（dependent）\n",
    "* 目的語: 述語からdobj関係にある子（dependent）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memo\n",
    "governor→dependentとすると、\n",
    "* nsubj : 述語→主語\n",
    "* dobj : 述語→目的語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "others\tinvolve\tgeneration\n",
      "understanding\tenabling\tcomputers\n",
      "Turing\tpublished\tarticle\n",
      "experiment\tinvolved\ttranslation\n",
      "ELIZA\tprovided\tinteraction\n",
      "ELIZA\tprovide\tresponse\n",
      "patient\texceeded\tbase\n",
      "which\tstructured\tinformation\n",
      "that\tunderlies\tapproach\n",
      "underpinnings\tdiscouraged\tsort\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "systems\trely\twhich\n",
      "that\tcontains\terrors\n",
      "implementations\tinvolved\tcoding\n",
      "algorithms\ttake\tset\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "they\texpress\tcertainty\n",
      "models\thave\tadvantage\n",
      "Systems\thave\tadvantages\n",
      "Automatic\tmake\tuse\n",
      "that\tmake\tdecisions\n"
     ]
    }
   ],
   "source": [
    "for sentence_tag in list(root.iter(\"sentences\"))[0].iter(\"sentence\"):\n",
    "    nodes = {0: \"ROOT\"}\n",
    "    for token_tag in sentence_tag.iter(\"token\"):\n",
    "        i = token_tag.get(\"id\")\n",
    "        nodes[i] = list(token_tag)[0].text\n",
    "\n",
    "    dependencies_tag = list(sentence_tag.iter(\"dependencies\"))[1]\n",
    "    nsubj, dobj = {}, {}\n",
    "    for dep_tag in list(dependencies_tag):\n",
    "        edge = list(dep_tag)\n",
    "        governor, dependent = edge[0].get(\"idx\"), edge[1].get(\"idx\")\n",
    "        if dep_tag.get(\"type\") == \"nsubj\":\n",
    "            nsubj[governor] = dependent\n",
    "        elif dep_tag.get(\"type\") == \"dobj\":\n",
    "            dobj[governor] = dependent\n",
    "\n",
    "    for predicate in set(nsubj.keys()) & set(dobj.keys()):\n",
    "        args = (nodes[nsubj[predicate]], nodes[predicate], nodes[dobj[predicate]])\n",
    "        print(\"%s\\t%s\\t%s\" % args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59. S式の解析\n",
    "Stanford Core NLPの句構造解析の結果（S式）を読み込み，文中のすべての名詞句（NP）を表示せよ．入れ子になっている名詞句もすべて表示すること．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memo\n",
    "As such, NLP is related to the area of humani-computer interaction.\n",
    "```\n",
    "(ROOT (S (PP (IN As) (NP (JJ such))) (, ,) (NP (NN NLP)) (VP (VBZ is) (ADJP (VBN related) (PP (TO to) (NP (NP (DT the) (NN area)) (PP (IN of) (NP (JJ humani-computer) (NN interaction))))))) (. .)))\n",
    "```\n",
    "```\n",
    "(NP (JJ such))\n",
    "(NP (NN NLP))\n",
    "(NP (NP (DT the) (NN area)) (PP (IN of) (NP (JJ humani-computer) (NN interaction))))\n",
    "(NP (DT the) (NN area))\n",
    "(NP (JJ humani-computer) (NN interaction))\n",
    "```\n",
    "* such\n",
    "* NLP\n",
    "* the area of humani-computer interaction\n",
    "* the area\n",
    "* humani-computer interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_NPs(s_formula: str):\n",
    "    pos, word = re.search(r\"\\((.*?) (.*)\\)\", s_formula).group(1, 2)\n",
    "\n",
    "    if word[0] == \"(\" and word[-1] == \")\":\n",
    "        depth, idx, idx_start = 0, 0, 0\n",
    "        while idx < len(word):\n",
    "            if word[idx] == \"(\":\n",
    "                depth += 1\n",
    "            elif word[idx] == \")\":\n",
    "                depth -= 1\n",
    "            if depth == 0:\n",
    "                print_NPs(word[idx_start:idx+1])\n",
    "                idx += 2\n",
    "                idx_start = idx\n",
    "            else:\n",
    "                idx += 1\n",
    "\n",
    "    if pos == \"NP\":\n",
    "        nps, np, is_bracket, is_blank = [], \"\", False, False\n",
    "        for char in word:\n",
    "            if char == \"(\":\n",
    "                is_bracket, is_blank = True, False\n",
    "                continue\n",
    "            elif char == \" \" and is_bracket:\n",
    "                is_blank = True\n",
    "                continue\n",
    "            elif char == \")\" and np != \"\":\n",
    "                nps.append(np)\n",
    "                is_bracket, is_blank, np = False, False, \"\"\n",
    "                continue\n",
    "            if is_bracket and is_blank:\n",
    "                np += char\n",
    "        print(\" \".join(nps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "Wikipedia\n",
      "the free encyclopedia Natural language processing\n",
      "NLP\n",
      "the free encyclopedia Natural language processing -LRB- NLP -RRB-\n",
      "a field\n",
      "computer science\n",
      "a field of computer science\n",
      "artificial intelligence\n",
      "linguistics\n",
      "the interactions\n",
      "computers\n",
      "human -LRB- natural -RRB- languages\n",
      "computers and human -LRB- natural -RRB- languages\n",
      "the interactions between computers and human -LRB- natural -RRB- languages\n",
      "linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "such\n",
      "NLP\n",
      "the area\n",
      "humani-computer interaction\n",
      "the area of humani-computer interaction\n",
      "Many challenges\n",
      "NLP\n",
      "Many challenges in NLP\n",
      "natural language understanding\n",
      "natural language understanding , that is ,\n",
      "computers\n",
      "meaning\n",
      "human or natural language input\n",
      "others\n",
      "natural language generation\n",
      "History The history\n",
      "NLP\n",
      "History The history of NLP\n",
      "the 1950s\n",
      "work\n",
      "earlier periods\n",
      "1950\n",
      "Alan Turing\n",
      "an article\n",
      "Computing Machinery and Intelligence\n",
      "the Turing test\n",
      "a criterion\n",
      "intelligence\n",
      "a criterion of intelligence\n",
      "an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence\n",
      "The Georgetown experiment\n",
      "1954\n",
      "The Georgetown experiment in 1954\n",
      "fully automatic translation\n",
      "more than sixty Russian sentences\n",
      "fully automatic translation of more than sixty Russian sentences\n",
      "English\n",
      "The authors\n",
      "three or five years\n",
      "machine translation\n",
      "a solved problem\n",
      "real progress\n",
      "the ALPAC report\n",
      "1966\n",
      "long research\n",
      "the expectations\n",
      "the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations\n",
      "machine\n",
      "translation\n",
      "Little further research\n",
      "machine translation\n",
      "Little further research in machine translation\n",
      "the late 1980s\n",
      "the first statistical machine\n",
      "translation systems\n",
      "the first statistical machine translation systems\n",
      "the late 1980s , when the first statistical machine translation systems were developed\n",
      "Some notably successful NLP systems\n",
      "the 1960s\n",
      "Some notably successful NLP systems developed in the 1960s\n",
      "SHRDLU\n",
      "a natural language system\n",
      "restricted\n",
      "blocks worlds\n",
      "restricted `` blocks worlds ''\n",
      "restricted vocabularies\n",
      "a natural language system working in restricted `` blocks worlds '' with restricted vocabularies\n",
      "SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies\n",
      "ELIZA\n",
      "a simulation\n",
      "a Rogerian psychotherapist\n",
      "a simulation of a Rogerian psychotherapist\n",
      "ELIZA , a simulation of a Rogerian psychotherapist ,\n",
      "Joseph Weizenbaum\n",
      "1964 to 1966\n",
      "Joseph Weizenbaum between 1964 to 1966\n",
      "almost no information\n",
      "human thought or emotion\n",
      "ELIZA\n",
      "a startlingly human-like interaction\n",
      "the `` patient ''\n",
      "the very small knowledge base\n",
      "ELIZA\n",
      "a generic response\n",
      "example\n",
      "My head\n",
      "a generic response , for example , responding to `` My head hurts\n",
      "you\n",
      "your head\n",
      ".\n",
      "the 1970s\n",
      "many programmers\n",
      "conceptual\n",
      "ontologies '\n",
      "conceptual ontologies '\n",
      "real-world information\n",
      "computer-understandable data\n",
      "conceptual ontologies ' , which structured real-world information into computer-understandable data\n",
      "Examples\n",
      "MARGIE\n",
      "Schank\n",
      "1975\n",
      "MARGIE -LRB- Schank , 1975 -RRB-\n",
      "SAM\n",
      "Cullingford\n",
      "1978\n",
      "SAM -LRB- Cullingford , 1978 -RRB-\n",
      "PAM\n",
      "Wilensky\n",
      "1978\n",
      "PAM -LRB- Wilensky , 1978 -RRB-\n",
      "TaleSpin\n",
      "Meehan\n",
      "1976\n",
      "TaleSpin -LRB- Meehan , 1976 -RRB-\n",
      "QUALM\n",
      "Lehnert\n",
      "1977\n",
      "Lehnert , 1977\n",
      "QUALM -LRB- Lehnert , 1977 -RRB-\n",
      "Politics\n",
      "Carbonell\n",
      "1979\n",
      "Politics -LRB- Carbonell , 1979 -RRB-\n",
      "Plot Units\n",
      "Lehnert 1981\n",
      "Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "MARGIE -LRB- Schank , 1975 -RRB- , SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "this time\n",
      "many chatterbots\n",
      "PARRY , Racter , and Jabberwacky\n",
      "the 1980s\n",
      "most NLP systems\n",
      "complex sets\n",
      "hand-written rules\n",
      "complex sets of hand-written rules\n",
      "the late 1980s\n",
      "there\n",
      "a revolution\n",
      "NLP\n",
      "a revolution in NLP\n",
      "the introduction\n",
      "machine learning algorithms\n",
      "language processing\n",
      "machine learning algorithms for language processing\n",
      "the introduction of machine learning algorithms for language processing\n",
      "This\n",
      "both the steady increase\n",
      "computational power\n",
      "Moore 's\n",
      "Moore 's Law\n",
      "the gradual lessening\n",
      "the dominance\n",
      "Chomskyan theories\n",
      "the dominance of Chomskyan theories\n",
      "linguistics\n",
      "e.g.\n",
      "transformational grammar\n",
      "e.g. transformational grammar\n",
      "linguistics -LRB- e.g. transformational grammar -RRB-\n",
      "theoretical underpinnings\n",
      "the sort\n",
      "corpus linguistics\n",
      "the machine-learning approach\n",
      "language processing\n",
      "the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "Some\n",
      "the earliest-used machine\n",
      "algorithms\n",
      "decision trees\n",
      "algorithms , such as decision trees ,\n",
      "the earliest-used machine learning algorithms , such as decision trees ,\n",
      "Some of the earliest-used machine learning algorithms , such as decision trees ,\n",
      "systems\n",
      "hard if-then rules\n",
      "existing hand-written rules\n",
      "hard if-then rules similar to existing hand-written rules\n",
      "systems of hard if-then rules similar to existing hand-written rules\n",
      "Part\n",
      "speech\n",
      "Part of speech\n",
      "the use\n",
      "Hidden Markov Models\n",
      "the use of Hidden Markov Models\n",
      "NLP\n",
      "research\n",
      "statistical models\n",
      "soft , probabilistic decisions\n",
      "real-valued weights\n",
      "the features\n",
      "the input data\n",
      "the features making up the input data\n",
      "statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data\n",
      "The cache language models\n",
      "many speech recognition systems\n",
      "The cache language models upon which many speech recognition systems now rely\n",
      "examples\n",
      "such statistical models\n",
      "examples of such statistical models\n",
      "Such models\n",
      "unfamiliar input\n",
      "input\n",
      "errors\n",
      "real-world data\n",
      "errors -LRB- as is very common for real-world data -RRB-\n",
      "input that contains errors -LRB- as is very common for real-world data -RRB-\n",
      "unfamiliar input , especially input that contains errors -LRB- as is very common for real-world data -RRB- ,\n",
      "more reliable results\n",
      "a larger system\n",
      "multiple subtasks\n",
      "a larger system comprising multiple subtasks\n",
      "Many\n",
      "the notable early successes\n",
      "Many of the notable early successes\n",
      "the field\n",
      "machine translation\n",
      "IBM Research\n",
      "more complicated statistical models\n",
      "machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed\n",
      "the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed\n",
      "These systems\n",
      "advantage\n",
      "existing multilingual textual corpora\n",
      "the Parliament\n",
      "Canada\n",
      "the European Union\n",
      "Canada and the European Union\n",
      "the Parliament of Canada and the European Union\n",
      "a result\n",
      "laws\n",
      "the translation\n",
      "all governmental proceedings\n",
      "the translation of all governmental proceedings\n",
      "all official languages\n",
      "the corresponding systems\n",
      "government\n",
      "the corresponding systems of government\n",
      "all official languages of the corresponding systems of government\n",
      "laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "most other systems\n",
      "corpora\n",
      "the tasks\n",
      "these systems\n",
      "these systems , which was -LRB- and often continues to be -RRB-\n",
      "the tasks implemented by these systems , which was -LRB- and often continues to be -RRB-\n",
      "a major limitation\n",
      "the success\n",
      "these systems\n",
      "the success of these systems\n",
      "a major limitation in the success of these systems\n",
      "a result\n",
      "a great deal\n",
      "research\n",
      "a great deal of research\n",
      "methods\n",
      "more\n",
      "limited amounts\n",
      "data\n",
      "limited amounts of data\n",
      "more effectively learning from limited amounts of data\n",
      "methods of more effectively learning from limited amounts of data\n",
      "Recent research\n",
      "unsupervised and semi-supervised learning algorithms\n",
      "Such algorithms\n",
      "data\n",
      "the desired answers\n",
      "data that has not been hand-annotated with the desired answers\n",
      "a combination\n",
      "annotated and non-annotated data\n",
      "a combination of annotated and non-annotated data\n",
      "this task\n",
      "supervised learning\n",
      "less accurate results\n",
      "a given amount\n",
      "input data\n",
      "a given amount of input data\n",
      "less accurate results for a given amount of input data\n",
      "there\n",
      "an enormous amount\n",
      "non-annotated data\n",
      "non-annotated data available\n",
      "an enormous amount of non-annotated data available\n",
      "other things\n",
      "the entire content\n",
      "the World Wide Web\n",
      "the entire content of the World Wide Web\n",
      "the inferior results\n",
      "an enormous amount of non-annotated data available -LRB- including , among other things , the entire content of the World Wide Web -RRB- , which can often make up for the inferior results\n",
      "NLP\n",
      "machine learning Modern NLP algorithms\n",
      "NLP using machine learning Modern NLP algorithms\n",
      "machine learning\n",
      "statistical machine learning\n",
      "machine learning , especially statistical machine learning\n",
      "The paradigm\n",
      "machine learning\n",
      "The paradigm of machine learning\n",
      "that\n",
      "most prior attempts\n",
      "that of most prior attempts\n",
      "language processing\n",
      "implementations\n",
      "language-processing tasks\n",
      "implementations of language-processing tasks\n",
      "the direct hand coding\n",
      "large sets\n",
      "rules\n",
      "large sets of rules\n",
      "the direct hand coding of large sets of rules\n",
      "The machine-learning paradigm\n",
      "general learning algorithms\n",
      "general learning algorithms - often\n",
      "statistical inference\n",
      "such rules\n",
      "the analysis\n",
      "large corpora\n",
      "typical real-world examples\n",
      "large corpora of typical real-world examples\n",
      "the analysis of large corpora of typical real-world examples\n",
      "A corpus\n",
      "plural\n",
      "`` corpora ''\n",
      "plural , `` corpora ''\n",
      "A corpus -LRB- plural , `` corpora '' -RRB-\n",
      "a set\n",
      "documents\n",
      "individual sentences\n",
      "the correct values\n",
      "documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned\n",
      "a set of documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned\n",
      "Many different classes\n",
      "machine learning algorithms\n",
      "Many different classes of machine learning algorithms\n",
      "NLP tasks\n",
      "These algorithms\n",
      "as input\n",
      "a large set\n",
      "`` features ''\n",
      "the input data\n",
      "`` features '' that are generated from the input data\n",
      "a large set of `` features '' that are generated from the input data\n",
      "Some\n",
      "the earliest-used algorithms\n",
      "decision trees\n",
      "Some of the earliest-used algorithms , such as decision trees ,\n",
      "systems\n",
      "hard if-then rules\n",
      "the systems\n",
      "hand-written rules\n",
      "the systems of hand-written rules that were then common\n",
      "hard if-then rules similar to the systems of hand-written rules that were then common\n",
      "systems of hard if-then rules similar to the systems of hand-written rules that were then common\n",
      "research\n",
      "statistical models\n",
      "soft , probabilistic decisions\n",
      "real-valued weights\n",
      "each input feature\n",
      "statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature\n",
      "Such models\n",
      "the advantage\n",
      "they\n",
      "the relative certainty\n",
      "many different possible answers\n",
      "only one\n",
      "many different possible answers rather than only one\n",
      "the relative certainty of many different possible answers rather than only one\n",
      "more reliable results\n",
      "such a model\n",
      "a component\n",
      "a larger system\n",
      "a component of a larger system\n",
      "Systems\n",
      "machine-learning algorithms\n",
      "Systems based on machine-learning algorithms\n",
      "many advantages\n",
      "hand-produced rules\n",
      "many advantages over hand-produced rules\n",
      "The learning procedures\n",
      "machine learning\n",
      "The learning procedures used during machine learning\n",
      "the most common cases\n",
      "rules\n",
      "hand\n",
      "it\n",
      "all\n",
      "the effort\n",
      "the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed\n",
      "Automatic\n",
      "procedures\n",
      "Automatic learning procedures\n",
      "use\n",
      "statistical inference algorithms\n",
      "use of statistical inference algorithms\n",
      "models\n",
      "unfamiliar input\n",
      "words or structures\n",
      "words or structures that have not been seen before\n",
      "e.g.\n",
      "words or words\n",
      "words or words accidentally omitted\n",
      "e.g. with misspelled words or words accidentally omitted\n",
      "erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-\n",
      "models that are robust to unfamiliar input -LRB- e.g. containing words or structures that have not been seen before -RRB- and to erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-\n",
      "such input\n",
      "hand-written rules\n",
      "such input gracefully with hand-written rules -- or more\n",
      "systems\n",
      "hand-written rules\n",
      "soft decisions\n",
      "soft decisions -- extremely difficult , error-prone and time-consuming\n",
      "systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming\n",
      "Systems\n",
      "the rules\n",
      "Systems based on automatically learning the rules\n",
      "more input data\n",
      "systems\n",
      "hand-written rules\n",
      "systems based on hand-written rules\n",
      "the complexity\n",
      "the rules\n",
      "a much more difficult task\n",
      "the rules , which is a much more difficult task\n",
      "the complexity of the rules , which is a much more difficult task\n",
      "there\n",
      "a limit\n",
      "the complexity\n",
      "systems\n",
      "hand-crafted rules\n",
      "the systems\n",
      "hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "more data\n",
      "input\n",
      "machine-learning systems\n",
      "a corresponding increase\n",
      "the number\n",
      "man-hours\n",
      "the number of man-hours\n",
      "a corresponding increase in the number of man-hours\n",
      "significant increases\n",
      "the complexity\n",
      "the annotation process\n",
      "the complexity of the annotation process\n",
      "significant increases in the complexity of the annotation process\n",
      "The subfield\n",
      "NLP\n",
      "approaches\n",
      "Natural Language Learning\n",
      "NLL\n",
      "Natural Language Learning -LRB- NLL -RRB-\n",
      "its conference CoNLL and peak body\n",
      "SIGNLL\n",
      "NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL\n",
      "The subfield of NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL\n",
      "ACL\n",
      "their links\n",
      "Computational Linguistics\n",
      "Language Acquisition\n",
      "Computational Linguistics and Language Acquisition\n",
      "the aims\n",
      "computational language\n",
      "research\n",
      "computational language learning research\n",
      "the aims of computational language learning research\n",
      "more\n",
      "human language acquisition\n",
      "psycholinguistics\n",
      "human language acquisition , or psycholinguistics\n",
      "NLL\n",
      "the related field\n",
      "Computational Psycholinguistics\n",
      "the related field of Computational Psycholinguistics\n"
     ]
    }
   ],
   "source": [
    "parses = [parse.text for parse in root.iter(\"parse\")]\n",
    "parse = parses[1]\n",
    "for parse in parses:\n",
    "    print_NPs(parse.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
